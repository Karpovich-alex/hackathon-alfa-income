{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851c975f",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "85adafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "import lightgbm\n",
    "import catboost\n",
    "import optuna\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f27377",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "133fea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dt</th>\n",
       "      <th>target</th>\n",
       "      <th>turn_cur_cr_avg_act_v2</th>\n",
       "      <th>salary_6to12m_avg</th>\n",
       "      <th>hdb_bki_total_max_limit</th>\n",
       "      <th>dp_ils_paymentssum_avg_12m</th>\n",
       "      <th>hdb_bki_total_cc_max_limit</th>\n",
       "      <th>incomeValue</th>\n",
       "      <th>gender</th>\n",
       "      <th>...</th>\n",
       "      <th>dp_ils_uniq_companies_1y</th>\n",
       "      <th>avg_6m_travel</th>\n",
       "      <th>avg_6m_government_services</th>\n",
       "      <th>hdb_bki_active_cc_max_overdue</th>\n",
       "      <th>total_rur_amt_cm_avg_period_days_ago_v2</th>\n",
       "      <th>label_Above_1M_share_r1</th>\n",
       "      <th>transaction_category_supermarket_sum_cnt_d15</th>\n",
       "      <th>max_balance_rur_amt_1m_af</th>\n",
       "      <th>w</th>\n",
       "      <th>first_salary_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>109324,47632478633</td>\n",
       "      <td>1465144,96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52800.0</td>\n",
       "      <td>365346,244633755</td>\n",
       "      <td>23213.0</td>\n",
       "      <td>97366,0</td>\n",
       "      <td>Женский</td>\n",
       "      <td>...</td>\n",
       "      <td>1,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>57,0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297,0</td>\n",
       "      <td>0,02702702702702703</td>\n",
       "      <td>9,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,3012172807640372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>25558,02866242038</td>\n",
       "      <td>303593,66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>32580,0</td>\n",
       "      <td>Женский</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,0</td>\n",
       "      <td>707,0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>30245,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,6957996079578388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>40666,753097982706</td>\n",
       "      <td>490754,01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>96866,0</td>\n",
       "      <td>Женский</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>422,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210322,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>20,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,5159704060557002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>43856,67205839414</td>\n",
       "      <td>219875,12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>43860,0</td>\n",
       "      <td>Мужской</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7187,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>7,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,4780029003784456</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>130420,85199232883</td>\n",
       "      <td>1750241,8449999997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>83815,0</td>\n",
       "      <td>Женский</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,0</td>\n",
       "      <td>84,0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690038,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,5523135540134384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         dt              target turn_cur_cr_avg_act_v2 salary_6to12m_avg  \\\n",
       "0   2 2024-04-30  109324,47632478633             1465144,96               NaN   \n",
       "1   4 2024-02-29   25558,02866242038              303593,66               NaN   \n",
       "2   5 2024-02-29  40666,753097982706              490754,01               NaN   \n",
       "3   6 2024-04-30   43856,67205839414              219875,12               NaN   \n",
       "4   7 2024-04-30  130420,85199232883     1750241,8449999997               NaN   \n",
       "\n",
       "   hdb_bki_total_max_limit dp_ils_paymentssum_avg_12m  \\\n",
       "0                  52800.0           365346,244633755   \n",
       "1                 260200.0                        NaN   \n",
       "2                2000000.0                        NaN   \n",
       "3                  75000.0                        NaN   \n",
       "4                1000000.0                        NaN   \n",
       "\n",
       "   hdb_bki_total_cc_max_limit incomeValue   gender  ...  \\\n",
       "0                     23213.0     97366,0  Женский  ...   \n",
       "1                     10000.0     32580,0  Женский  ...   \n",
       "2                     90000.0     96866,0  Женский  ...   \n",
       "3                     75000.0     43860,0  Мужской  ...   \n",
       "4                    240000.0     83815,0  Женский  ...   \n",
       "\n",
       "  dp_ils_uniq_companies_1y avg_6m_travel avg_6m_government_services  \\\n",
       "0                      1,0           0,0                       57,0   \n",
       "1                      NaN           0,0                      707,0   \n",
       "2                      NaN         422,0                        0,0   \n",
       "3                      NaN           0,0                        0,0   \n",
       "4                      NaN           0,0                       84,0   \n",
       "\n",
       "  hdb_bki_active_cc_max_overdue  total_rur_amt_cm_avg_period_days_ago_v2  \\\n",
       "0                           0.0                                    297,0   \n",
       "1                          67.0                                  30245,0   \n",
       "2                           0.0                                 210322,0   \n",
       "3                           0.0                                   7187,0   \n",
       "4                           0.0                                 690038,0   \n",
       "\n",
       "  label_Above_1M_share_r1 transaction_category_supermarket_sum_cnt_d15  \\\n",
       "0     0,02702702702702703                                          9,0   \n",
       "1                     NaN                                          2,0   \n",
       "2                     0,0                                         20,0   \n",
       "3                     0,0                                          7,0   \n",
       "4                     0,0                                          9,0   \n",
       "\n",
       "  max_balance_rur_amt_1m_af                   w first_salary_income  \n",
       "0                       NaN  0,3012172807640372                 NaN  \n",
       "1                       NaN  0,6957996079578388                 NaN  \n",
       "2                       NaN  0,5159704060557002                 NaN  \n",
       "3                       NaN  0,4780029003784456                 NaN  \n",
       "4                       NaN  0,5523135540134384                 NaN  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/hackathon_income_train.csv', delimiter=';', decimal='.', parse_dates=['dt'], dayfirst=False)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "8e0b0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76786 entries, 0 to 76785\n",
      "Columns: 224 entries, id to first_salary_income\n",
      "dtypes: datetime64[ns](1), float64(34), int64(1), object(188)\n",
      "memory usage: 131.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "77dd046e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dt</th>\n",
       "      <th>turn_cur_cr_avg_act_v2</th>\n",
       "      <th>salary_6to12m_avg</th>\n",
       "      <th>hdb_bki_total_max_limit</th>\n",
       "      <th>dp_ils_paymentssum_avg_12m</th>\n",
       "      <th>hdb_bki_total_cc_max_limit</th>\n",
       "      <th>incomeValue</th>\n",
       "      <th>gender</th>\n",
       "      <th>avg_cur_cr_turn</th>\n",
       "      <th>...</th>\n",
       "      <th>total_sum</th>\n",
       "      <th>dp_ils_uniq_companies_1y</th>\n",
       "      <th>avg_6m_travel</th>\n",
       "      <th>avg_6m_government_services</th>\n",
       "      <th>hdb_bki_active_cc_max_overdue</th>\n",
       "      <th>total_rur_amt_cm_avg_period_days_ago_v2</th>\n",
       "      <th>label_Above_1M_share_r1</th>\n",
       "      <th>transaction_category_supermarket_sum_cnt_d15</th>\n",
       "      <th>max_balance_rur_amt_1m_af</th>\n",
       "      <th>first_salary_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>805319,38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61137.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>159999,0</td>\n",
       "      <td>Женский</td>\n",
       "      <td>69740,0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80228,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>1,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>306240,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>949500.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>108834,0</td>\n",
       "      <td>Мужской</td>\n",
       "      <td>63513,0</td>\n",
       "      <td>...</td>\n",
       "      <td>0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24888,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>164908,72999999998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178000.0</td>\n",
       "      <td>59203,0</td>\n",
       "      <td>Женский</td>\n",
       "      <td>132,0</td>\n",
       "      <td>...</td>\n",
       "      <td>38630,630000000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>2363.9</td>\n",
       "      <td>223,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>2374846,42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25500.00</td>\n",
       "      <td>126247,44835851202</td>\n",
       "      <td>4999.0</td>\n",
       "      <td>180906,0</td>\n",
       "      <td>Женский</td>\n",
       "      <td>290339,0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,0</td>\n",
       "      <td>800,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25734,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>7,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>735902,71</td>\n",
       "      <td>47828,145620567375</td>\n",
       "      <td>60000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>24922,0</td>\n",
       "      <td>Мужской</td>\n",
       "      <td>76924,0</td>\n",
       "      <td>...</td>\n",
       "      <td>0,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1214,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>15,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         dt turn_cur_cr_avg_act_v2   salary_6to12m_avg  \\\n",
       "0   0 2024-08-31              805319,38                 NaN   \n",
       "1   1 2024-10-31               306240,0                 NaN   \n",
       "2   3 2024-09-30     164908,72999999998                 NaN   \n",
       "3   9 2024-10-31             2374846,42                 NaN   \n",
       "4  11 2024-11-30              735902,71  47828,145620567375   \n",
       "\n",
       "   hdb_bki_total_max_limit dp_ils_paymentssum_avg_12m  \\\n",
       "0                 61137.47                        NaN   \n",
       "1                949500.00                        NaN   \n",
       "2                178000.00                        NaN   \n",
       "3                 25500.00         126247,44835851202   \n",
       "4                 60000.00                        NaN   \n",
       "\n",
       "   hdb_bki_total_cc_max_limit incomeValue   gender avg_cur_cr_turn  ...  \\\n",
       "0                     60000.0    159999,0  Женский         69740,0  ...   \n",
       "1                    230000.0    108834,0  Мужской         63513,0  ...   \n",
       "2                    178000.0     59203,0  Женский           132,0  ...   \n",
       "3                      4999.0    180906,0  Женский        290339,0  ...   \n",
       "4                     60000.0     24922,0  Мужской         76924,0  ...   \n",
       "\n",
       "            total_sum dp_ils_uniq_companies_1y avg_6m_travel  \\\n",
       "0                 NaN                      NaN           0,0   \n",
       "1                 0,0                      NaN           0,0   \n",
       "2  38630,630000000005                      NaN           0,0   \n",
       "3                 NaN                      3,0         800,0   \n",
       "4                 0,0                      NaN           0,0   \n",
       "\n",
       "   avg_6m_government_services hdb_bki_active_cc_max_overdue  \\\n",
       "0                         0,0                           NaN   \n",
       "1                         0,0                           0.0   \n",
       "2                         0,0                        2363.9   \n",
       "3                         0,0                           NaN   \n",
       "4                         0,0                           0.0   \n",
       "\n",
       "  total_rur_amt_cm_avg_period_days_ago_v2 label_Above_1M_share_r1  \\\n",
       "0                                 80228,0                     0,0   \n",
       "1                                 24888,0                     0,0   \n",
       "2                                   223,0                     NaN   \n",
       "3                                 25734,0                     0,0   \n",
       "4                                  1214,0                     0,0   \n",
       "\n",
       "  transaction_category_supermarket_sum_cnt_d15 max_balance_rur_amt_1m_af  \\\n",
       "0                                          1,0                       NaN   \n",
       "1                                          NaN                       NaN   \n",
       "2                                          NaN                       NaN   \n",
       "3                                          7,0                       0,0   \n",
       "4                                         15,0                       NaN   \n",
       "\n",
       "  first_salary_income  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/hackathon_income_test.csv', delimiter=';', decimal='.', parse_dates=['dt'], dayfirst=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "2ed6af16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dp_address_unique_regions'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ae0b6116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['dp_address_unique_regions'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "6f10a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '22', '25', '39', '61', '47', '77,50', '78', '74', '52', '71',\n",
       "       '66', '59,66', '24', '16', '91,77,23', '23', '58', '67', '55',\n",
       "       '35', '64', '77', '18', '50', '26', '50,12', '59', '86', '02',\n",
       "       '30', '36', '38', '29', '72', '54', '73', '40', '61,23', '32',\n",
       "       '42', '37', '50,25', '35,50', '77,21', '34', '05', '77,14', '76',\n",
       "       '10,59', '66,72', '24,78', '40,77', '14', '11', '27', '33,52',\n",
       "       '70', '46', '38,16,63', '21', '69', '74,55', '19', '63', '61,47',\n",
       "       '75', '43,66', '89', '03', '62', '57,50', '12', '78,86', '56',\n",
       "       '77,68', '47,78', '56,66', '68', '16,02', '47,72', '86,72', '51',\n",
       "       '33', '23,66', '42,54', '10', '50,23', '60', '77,78', '02,16',\n",
       "       '43,78', '50,77,16', '31', '43', '78,47', '45', '02,63', '50,77',\n",
       "       '48', '16,12', '43,77', '94,61', '77,63', '57', '77,67', '22,42',\n",
       "       '77,62', '86,77', '34,78', '13', '65', '71,54', '77,02,50',\n",
       "       '26,42', '15,78', '21,77', '42,50', '50,32', '50,38', '23,31',\n",
       "       '07,34', '77,29', '61,01', '91', '72,74', '60,78', '64,50',\n",
       "       '77,69', '18,14', '50,20', '91,77', '53', '31,78', '91,50',\n",
       "       '77,91', '36,78', '78,38', '78,59', '66,93', '52,36', '23,86',\n",
       "       '16,18', '37,44', '25,27', '01,23', '50,21', '77,26', '07',\n",
       "       '24,47', '24,75', '77,28', '61,77', '66,74', '44', '64,54',\n",
       "       '77,57', '23,16', '78,77', '77,16', '79', '36,50', '02,86',\n",
       "       '89,63', '23,03', '68,77', '31,77', '77,54', '50,64', '23,01',\n",
       "       '78,29', '73,78', '78,73', '50,26', '08', '01', '86,66', '34,77',\n",
       "       '28', '77,18', '25,77', '78,25', '94', '50,40', '92,25', '54,14',\n",
       "       '78,02', '72,45', '33,50', '69,47', '23,71', '24,23', '36,77',\n",
       "       '50,34', '86,02', '78,55', '78,54', '05,50', '35,77', '50,35',\n",
       "       '94,69', '77,22', '26,77', '21,16', '52,33', '23,50', '29,43',\n",
       "       '26,23', '43,58', '50,60', '78,42', '59,02', '03,38', '45,74',\n",
       "       '70,54', '70,77', '52,18', '77,34', '73,63', '22,77', '54,42',\n",
       "       '61,26', '50,13', '72,66', '22,50', '77,30', '36,71', '46,77',\n",
       "       '77,36', '33,77', '86,59', '59,77', '77,66', '50,61', '26,76',\n",
       "       '77,50,33', '14,78', '16,50,77', '23,72,86', '77,60', '77,56',\n",
       "       '77,23', '25,52', '16,66', '50,71', '78,26', '16,78,47', '50,70',\n",
       "       '50,55', '08,78', '74,50', '76,51', '68,50', '29,78', '56,70',\n",
       "       '15', '52,21', '55,16,78', '47,70', '64,77', '65,25', '23,08',\n",
       "       '31,34', '77,08', '78,66', '77,31', '23,78', '27,36', '23,42',\n",
       "       '78,74', '42,24', '55,86', '23,77', '70,42', '55,23', '36,52',\n",
       "       '54,55', '45,72', '36,68', '77,13', '78,30', '63,50,14', '57,36',\n",
       "       '55,89', '50,87,08', '50,37', '52,44', '86,23', '78,69', '78,16',\n",
       "       '47,33', '59,72', '77,40', '77,71', '23,61', '57,50,56', '78,64',\n",
       "       '73,50', '47,53', '54,23', '64,63', '15,77', '77,61', '29,50,34',\n",
       "       '27,28', '56,16', '50,67', '49', '74,78', '34,64', '63,23',\n",
       "       '23,34', '77,64', '63,73,77', '34,50', '74,77', '59,91', '39,76',\n",
       "       '95', '26,50', '23,57', '19,24', '11,78', '02,23', '44,50', '93',\n",
       "       '54,77,18', '07,77', '42,77', '63,77', '77,58', '91,74', '78,63',\n",
       "       '86,78', '40,78', '23,26', '66,23', '32,78', '50,08', '28,77',\n",
       "       '69,16', '11,52', '36,34', '78,94', '18,16', '50,18', '40,50',\n",
       "       '77,50,59', '28,23', '78,52', '94,77', '57,77', '74,86', '23,54',\n",
       "       '16,56', '24,54', '65,77', '77,24', '34,47', '35,24', '16,34',\n",
       "       '14,31', '66,59', '04', '78,39', '38,77', '04,54', '14,23',\n",
       "       '66,77', '48,36,50', '24,77', '02,77', '20', '77,59', '71,77',\n",
       "       '54,13', '50,68', '23,74', '50,63', '61,59', '77,76', '77,55',\n",
       "       '61,78', '74,66', '09,36', '54,59', '70,78', '42,70', '53,50',\n",
       "       '72,86', '78,36', '63,73', '55,77', '02,78', '79,27', '91,34',\n",
       "       '77,33', '78,35', '77,74', '42,23', '61,42', '02,71', '50,31',\n",
       "       '69,63', '37,50', '02,40', '14,77', '50,27', '77,38', '52,78',\n",
       "       '73,22', '52,69', '29,50,77', '63,47', '68,78', '91,47,23',\n",
       "       '56,77', '23,47', '24,73', '31,66', '71,50', '46,50', '24,19',\n",
       "       '52,77', '27,78', '25,23', '22,86', '77,42', '40,13', '76,50',\n",
       "       '31,50,23', '22,66', '77,05', '32,50', '23,67', '14,66',\n",
       "       '77,21,50', '92,78', '62,02', '24,70', '21,12', '38,58', '78,34',\n",
       "       '56,74', '66,18', '54,77', '78,53', '50,69', '23,09', '54,22',\n",
       "       '77,52', '52,50', '50,36', '05,77', '50,94', '50,74', '30,77',\n",
       "       '59,23', '65,27', '72,74,86', '10,29', '18,77', '34,23', '56,78',\n",
       "       '29,77', '03,77', '31,46', '78,71', '77,25', '50,78', '53,78',\n",
       "       '60,45', '78,21', '74,54', '32,77', '47,51', '02,50', '39,22',\n",
       "       '77,32', '24,50', '29,35', '43,24', '02,74', '22,54', '69,77',\n",
       "       '24,42', '23,24', '89,77', '13,77', '17', '30,34', '66,89',\n",
       "       '69,23', '74,23', '75,24', '63,78', '63,72', '91,92', '51,47',\n",
       "       '54,70', '01,50', '58,52', '76,29', '47,77', '39,78', '67,50,76',\n",
       "       '53,47', '91,23', '61,50', '54,39', '54,03', '47,69', '66,63',\n",
       "       '27,25', '77,39', '02,66', '33,44', '69,78', '30,39', '51,78',\n",
       "       '67,50', '50,58', '37,77', '86,45', '44,76', '76,77', '38,03',\n",
       "       '50,73', '78,61,47', '26,61', '50,16', '43,16', '02,18', '12,77',\n",
       "       '36,89', '19,03', '40,71', '77,46,50', '56,50', '26,47', '23,46',\n",
       "       '91,23,16', '30,50', '76,69', '03,75', '50,83', '71,23', '48,56',\n",
       "       '50,39', '74,02', '77,08,50', '66,54', '10,47', '36,22', '09',\n",
       "       '54,38', '31,23', '92', '47,37', '50,86', '50,75', '50,56',\n",
       "       '23,59', '86,01', '74,56', '77,20', '13,50', '89,72', '78,23',\n",
       "       '43,74', '86,22', '78,22', '77,15', '78,61', '23,76', '74,45',\n",
       "       '16,25', '93,47', '67,77', '62,50', '47,24', '36,48', '61,25',\n",
       "       '24,39', '19,77', '72,20', '23,38', '27,23', '33,54', '11,59',\n",
       "       '57,68', '16,77', '41,78', '50,22', '56,23', '47,26,78', '13,23',\n",
       "       '66,45', '54,25', '16,59', '54,75', '58,54', '23,62', '50,05',\n",
       "       '66,64', '36,03', '44,77', '42,16', '34,51', '02,64', '28,42',\n",
       "       '07,50', '71,77,67', '78,32', '56,71', '54,50', '94,78', '48,50',\n",
       "       '83', '06', '64,68', '78,11', '23,65', '17,54', '41', '95,61',\n",
       "       '78,68', '78,51', '91,61', '51,26', '76,37', '63,16', '93,50',\n",
       "       '23,48', '23,18', '77,46', '71,77,50', '78,43', '50,51,63',\n",
       "       '50,30', '42,78', '27,77', '09,77', '40,43', '08,77', '16,78',\n",
       "       '23,27', '78,19', '77,50,46', '62,37', '66,47', '25,54,23',\n",
       "       '23,91', '59,16', '78,50', '01,77', '64,26', '47,10', '50,42',\n",
       "       '15,47', '23,64', '16,21', '77,44', '18,50', '33,78', '77,11',\n",
       "       '54,73', '51,10', '16,43,11', '50,24', '34,08', '78,60', '50,57',\n",
       "       '03,70', '08,50', '78,05', '38,24', '47,89', '42,22', '13,78',\n",
       "       '76,47', '64,78', '87', '78,28', '77,07', '52,74', '48,77',\n",
       "       '18,43', '36,31', '61,28', '68,50,07', '67,77,37', '75,76',\n",
       "       '22,47', '47,02', '54,24', '34,66', '59,25', '27,63', '40,66',\n",
       "       '50,54', '58,77', '68,48', '50,78,69', '42,63', '68,36', '67,23',\n",
       "       '66,50', '38,78', '26,09', '36,06', '66,55', '32,23', '15,77,50',\n",
       "       '89,86', '64,34,37', '39,77', '66,78', '47,23', '78,08', '20,77',\n",
       "       '24,78,47', '51,29', '93,61', '77,27', '76,35', '24,22', '64,56',\n",
       "       '02,59', '66,24', '54,74', '45,54', '21,20', '55,72', '41,26',\n",
       "       '24,91', '73,16', '35,61,78', '45,77', '47,42', '55,34', '23,39',\n",
       "       '54,22,23', '26,07', '52,66,47', '26,66', '23,30', '52,13',\n",
       "       '66,14', '47,56', '77,70', '78,75', '72,89', '64,22', '77,73',\n",
       "       '77,86', '52,37', '26,78', '59,24', '77,72', '64,31', '77,37',\n",
       "       '49,40', '70,50', '78,64,47', '75,38', '77,35', '20,61', '60,47',\n",
       "       '50,89', '54,26', '16,73', '27,79', '25,41', '50,77,61', '22,24',\n",
       "       '55,52', '77,02', '43,50', '46,78,47', '14,24', '33,62', '92,50',\n",
       "       '19,54', '47,50', '42,52', '50,03', '66,94', '18,59', '54,78',\n",
       "       '04,22', '31,50', '21,50', '74,47', '14,50', '22,27', '24,77,57',\n",
       "       '40,77,50', '52,56', '10,78', '17,24', '86,50', '05,34', '11,50',\n",
       "       '77,30,50', '59,50', '23,56', '34,30', '61,44', '16,50', '13,64',\n",
       "       '52,11', '50,33', '72,77', '78,10', '59,18', '50,62', '26,39',\n",
       "       '24,38', '50,43', '78,18', '55,50', '78,29,83', '47,59', '32,57',\n",
       "       '25,78', '77,47', '78,37', '56,63', '47,26', '66,07', '75,23',\n",
       "       '78,24', '47,35', '18,78', '93,77', '78,27', '77,23,50', '50,28',\n",
       "       '42,72', '29,76', '51,23', '77,12', '39,42', '75,03', '61,93',\n",
       "       '50,02', '50,61,77', '23,89', '77,78,08', '50,23,91', '31,67',\n",
       "       '22,78', '52,63', '62,40', '91,78', '47,08', '47,60'], dtype=object)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.iloc[:,65].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "1a50d9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>признак</th>\n",
       "      <th>описание</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>Дата актуальности признаков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target</td>\n",
       "      <td>таргет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turn_cur_cr_avg_act_v2</td>\n",
       "      <td>Средний текущий кредитовый оборот по текущим с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salary_6to12m_avg</td>\n",
       "      <td>Усреднённая ЗП клиента за окно в минимум 6 мес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hdb_bki_total_max_limit</td>\n",
       "      <td>БКИ: Максимальный кредитный лимит по любому пр...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   признак                                           описание\n",
       "0                       dt                        Дата актуальности признаков\n",
       "1                   target                                             таргет\n",
       "2   turn_cur_cr_avg_act_v2  Средний текущий кредитовый оборот по текущим с...\n",
       "3        salary_6to12m_avg  Усреднённая ЗП клиента за окно в минимум 6 мес...\n",
       "4  hdb_bki_total_max_limit  БКИ: Максимальный кредитный лимит по любому пр..."
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('data/features_description.csv', delimiter=';', encoding='windows-1251')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "39afc5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 2)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620fa23",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54733389",
   "metadata": {},
   "source": [
    "# Проверка уникальности клиентов/записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "41f80308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data.id) & set(test_data.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b1b1f0",
   "metadata": {},
   "source": [
    "Пересекающихся клиентов нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "63772139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего записей: 76786\n",
      "Кол-во уникальных id: 76786\n"
     ]
    }
   ],
   "source": [
    "print(f'Всего записей: {train_data.shape[0]}\\nКол-во уникальных id: {train_data.id.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c80d4153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 4 типов данных: [dtype('int64') dtype('<M8[ns]') dtype('O') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "print(f'Всего {train_data.dtypes.nunique()} типов данных: {train_data.dtypes.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "c86751d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76786, 188)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select_dtypes(include='O').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "1f5994d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numeric_columns(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # Replace comma with dot for decimal conversion\n",
    "            df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
    "            # Convert to numeric, coercing errors to NaN\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "train_df = convert_numeric_columns(train_data)\n",
    "test_df = convert_numeric_columns(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "83b9af30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'adminarea', 'city_smart_name',\n",
       "       'dp_ewb_last_employment_position', 'addrref',\n",
       "       'dp_address_unique_regions', 'period_last_act_ad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.select_dtypes(include=['O']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3b8851c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_data.select_dtypes(include=['object']).columns:\n",
    "    train_df[col] = train_df[col].astype('category')\n",
    "    test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "badb4f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dt</th>\n",
       "      <th>target</th>\n",
       "      <th>turn_cur_cr_avg_act_v2</th>\n",
       "      <th>salary_6to12m_avg</th>\n",
       "      <th>hdb_bki_total_max_limit</th>\n",
       "      <th>dp_ils_paymentssum_avg_12m</th>\n",
       "      <th>hdb_bki_total_cc_max_limit</th>\n",
       "      <th>incomeValue</th>\n",
       "      <th>avg_cur_cr_turn</th>\n",
       "      <th>...</th>\n",
       "      <th>dp_ils_uniq_companies_1y</th>\n",
       "      <th>avg_6m_travel</th>\n",
       "      <th>avg_6m_government_services</th>\n",
       "      <th>hdb_bki_active_cc_max_overdue</th>\n",
       "      <th>total_rur_amt_cm_avg_period_days_ago_v2</th>\n",
       "      <th>label_Above_1M_share_r1</th>\n",
       "      <th>transaction_category_supermarket_sum_cnt_d15</th>\n",
       "      <th>max_balance_rur_amt_1m_af</th>\n",
       "      <th>w</th>\n",
       "      <th>first_salary_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76786.000000</td>\n",
       "      <td>76786</td>\n",
       "      <td>7.678600e+04</td>\n",
       "      <td>5.907800e+04</td>\n",
       "      <td>1.487500e+04</td>\n",
       "      <td>6.741300e+04</td>\n",
       "      <td>1.650300e+04</td>\n",
       "      <td>6.304100e+04</td>\n",
       "      <td>63817.000000</td>\n",
       "      <td>6.021400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>16589.000000</td>\n",
       "      <td>55130.000000</td>\n",
       "      <td>55130.000000</td>\n",
       "      <td>5.573300e+04</td>\n",
       "      <td>7.316600e+04</td>\n",
       "      <td>34010.000000</td>\n",
       "      <td>34934.000000</td>\n",
       "      <td>1.113300e+04</td>\n",
       "      <td>76786.000000</td>\n",
       "      <td>8.668000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75070.250540</td>\n",
       "      <td>2024-04-28 15:29:52.170447616</td>\n",
       "      <td>9.264824e+04</td>\n",
       "      <td>1.170105e+06</td>\n",
       "      <td>1.174897e+05</td>\n",
       "      <td>1.353383e+06</td>\n",
       "      <td>2.162228e+05</td>\n",
       "      <td>2.504806e+05</td>\n",
       "      <td>81682.344469</td>\n",
       "      <td>1.866825e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.454819</td>\n",
       "      <td>912.809305</td>\n",
       "      <td>275.162561</td>\n",
       "      <td>6.904705e+03</td>\n",
       "      <td>9.641689e+04</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>12.909286</td>\n",
       "      <td>1.360850e+05</td>\n",
       "      <td>0.569014</td>\n",
       "      <td>2.052949e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2024-01-31 00:00:00</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>2.000374e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.648938e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-7.982345e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37519.250000</td>\n",
       "      <td>2024-03-31 00:00:00</td>\n",
       "      <td>3.970997e+04</td>\n",
       "      <td>2.039768e+05</td>\n",
       "      <td>4.872909e+04</td>\n",
       "      <td>1.908000e+05</td>\n",
       "      <td>9.280878e+04</td>\n",
       "      <td>7.140000e+04</td>\n",
       "      <td>46223.000000</td>\n",
       "      <td>1.580175e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.235950</td>\n",
       "      <td>1.264576e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74975.500000</td>\n",
       "      <td>2024-04-30 00:00:00</td>\n",
       "      <td>6.275413e+04</td>\n",
       "      <td>5.940204e+05</td>\n",
       "      <td>7.309241e+04</td>\n",
       "      <td>5.772000e+05</td>\n",
       "      <td>1.497120e+05</td>\n",
       "      <td>1.550000e+05</td>\n",
       "      <td>67474.000000</td>\n",
       "      <td>7.436150e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.250000e+02</td>\n",
       "      <td>0.449424</td>\n",
       "      <td>1.769727e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112835.500000</td>\n",
       "      <td>2024-05-31 00:00:00</td>\n",
       "      <td>1.002017e+05</td>\n",
       "      <td>1.268697e+06</td>\n",
       "      <td>1.222903e+05</td>\n",
       "      <td>1.693000e+06</td>\n",
       "      <td>2.422720e+05</td>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>101340.000000</td>\n",
       "      <td>1.754025e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.879960e+03</td>\n",
       "      <td>1.978700e+04</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.058000e+03</td>\n",
       "      <td>0.680337</td>\n",
       "      <td>2.378084e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>149999.000000</td>\n",
       "      <td>2024-06-30 00:00:00</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>6.545863e+07</td>\n",
       "      <td>3.419392e+06</td>\n",
       "      <td>1.500000e+08</td>\n",
       "      <td>4.754632e+06</td>\n",
       "      <td>1.500000e+07</td>\n",
       "      <td>542084.000000</td>\n",
       "      <td>1.702021e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>287382.000000</td>\n",
       "      <td>310266.000000</td>\n",
       "      <td>1.519780e+06</td>\n",
       "      <td>4.263312e+07</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>2.374923e+08</td>\n",
       "      <td>2.570703</td>\n",
       "      <td>1.650302e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43362.283111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124090e+05</td>\n",
       "      <td>2.205263e+06</td>\n",
       "      <td>1.603782e+05</td>\n",
       "      <td>2.261767e+06</td>\n",
       "      <td>2.538178e+05</td>\n",
       "      <td>3.471460e+05</td>\n",
       "      <td>51306.983613</td>\n",
       "      <td>4.615432e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886676</td>\n",
       "      <td>6249.867314</td>\n",
       "      <td>2107.505699</td>\n",
       "      <td>3.522878e+04</td>\n",
       "      <td>5.695752e+05</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>11.214355</td>\n",
       "      <td>2.517752e+06</td>\n",
       "      <td>0.551835</td>\n",
       "      <td>1.515545e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                             dt        target  \\\n",
       "count   76786.000000                          76786  7.678600e+04   \n",
       "mean    75070.250540  2024-04-28 15:29:52.170447616  9.264824e+04   \n",
       "min         2.000000            2024-01-31 00:00:00  2.000000e+04   \n",
       "25%     37519.250000            2024-03-31 00:00:00  3.970997e+04   \n",
       "50%     74975.500000            2024-04-30 00:00:00  6.275413e+04   \n",
       "75%    112835.500000            2024-05-31 00:00:00  1.002017e+05   \n",
       "max    149999.000000            2024-06-30 00:00:00  1.500000e+06   \n",
       "std     43362.283111                            NaN  1.124090e+05   \n",
       "\n",
       "       turn_cur_cr_avg_act_v2  salary_6to12m_avg  hdb_bki_total_max_limit  \\\n",
       "count            5.907800e+04       1.487500e+04             6.741300e+04   \n",
       "mean             1.170105e+06       1.174897e+05             1.353383e+06   \n",
       "min              1.000000e-02       2.000374e+04             0.000000e+00   \n",
       "25%              2.039768e+05       4.872909e+04             1.908000e+05   \n",
       "50%              5.940204e+05       7.309241e+04             5.772000e+05   \n",
       "75%              1.268697e+06       1.222903e+05             1.693000e+06   \n",
       "max              6.545863e+07       3.419392e+06             1.500000e+08   \n",
       "std              2.205263e+06       1.603782e+05             2.261767e+06   \n",
       "\n",
       "       dp_ils_paymentssum_avg_12m  hdb_bki_total_cc_max_limit    incomeValue  \\\n",
       "count                1.650300e+04                6.304100e+04   63817.000000   \n",
       "mean                 2.162228e+05                2.504806e+05   81682.344469   \n",
       "min                  2.648938e+00                0.000000e+00       0.000000   \n",
       "25%                  9.280878e+04                7.140000e+04   46223.000000   \n",
       "50%                  1.497120e+05                1.550000e+05   67474.000000   \n",
       "75%                  2.422720e+05                3.000000e+05  101340.000000   \n",
       "max                  4.754632e+06                1.500000e+07  542084.000000   \n",
       "std                  2.538178e+05                3.471460e+05   51306.983613   \n",
       "\n",
       "       avg_cur_cr_turn  ...  dp_ils_uniq_companies_1y  avg_6m_travel  \\\n",
       "count     6.021400e+04  ...              16589.000000   55130.000000   \n",
       "mean      1.866825e+05  ...                  1.454819     912.809305   \n",
       "min       0.000000e+00  ...                  0.000000       0.000000   \n",
       "25%       1.580175e+04  ...                  1.000000       0.000000   \n",
       "50%       7.436150e+04  ...                  1.000000       0.000000   \n",
       "75%       1.754025e+05  ...                  2.000000       0.000000   \n",
       "max       1.702021e+07  ...                 15.000000  287382.000000   \n",
       "std       4.615432e+05  ...                  0.886676    6249.867314   \n",
       "\n",
       "       avg_6m_government_services  hdb_bki_active_cc_max_overdue  \\\n",
       "count                55130.000000                   5.573300e+04   \n",
       "mean                   275.162561                   6.904705e+03   \n",
       "min                      0.000000                   0.000000e+00   \n",
       "25%                      0.000000                   0.000000e+00   \n",
       "50%                      0.000000                   0.000000e+00   \n",
       "75%                      0.000000                   1.879960e+03   \n",
       "max                 310266.000000                   1.519780e+06   \n",
       "std                   2107.505699                   3.522878e+04   \n",
       "\n",
       "       total_rur_amt_cm_avg_period_days_ago_v2  label_Above_1M_share_r1  \\\n",
       "count                             7.316600e+04             34010.000000   \n",
       "mean                              9.641689e+04                 0.008593   \n",
       "min                               0.000000e+00                 0.000000   \n",
       "25%                               0.000000e+00                 0.000000   \n",
       "50%                               2.000000e+03                 0.000000   \n",
       "75%                               1.978700e+04                 0.007463   \n",
       "max                               4.263312e+07                 0.428571   \n",
       "std                               5.695752e+05                 0.022440   \n",
       "\n",
       "       transaction_category_supermarket_sum_cnt_d15  \\\n",
       "count                                  34934.000000   \n",
       "mean                                      12.909286   \n",
       "min                                        1.000000   \n",
       "25%                                        5.000000   \n",
       "50%                                       10.000000   \n",
       "75%                                       18.000000   \n",
       "max                                      133.000000   \n",
       "std                                       11.214355   \n",
       "\n",
       "       max_balance_rur_amt_1m_af             w  first_salary_income  \n",
       "count               1.113300e+04  76786.000000         8.668000e+03  \n",
       "mean                1.360850e+05      0.569014         2.052949e+05  \n",
       "min                -2.000000e+00      0.000021        -7.982345e+04  \n",
       "25%                 2.000000e+00      0.235950         1.264576e+05  \n",
       "50%                 5.250000e+02      0.449424         1.769727e+05  \n",
       "75%                 4.058000e+03      0.680337         2.378084e+05  \n",
       "max                 2.374923e+08      2.570703         1.650302e+06  \n",
       "std                 2.517752e+06      0.551835         1.515545e+05  \n",
       "\n",
       "[8 rows x 217 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "d65edcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt | Дата актуальности признаков\n",
      "target | таргет\n",
      "turn_cur_cr_avg_act_v2 | Средний текущий кредитовый оборот по текущим счетам за 12 месяцев\n",
      "salary_6to12m_avg | Усреднённая ЗП клиента за окно в минимум 6 месяцев и максимум 12 месяцев\n",
      "hdb_bki_total_max_limit | БКИ: Максимальный кредитный лимит по любому продукту за все время\n",
      "dp_ils_paymentssum_avg_12m | данные цифрового профиля\n",
      "hdb_bki_total_cc_max_limit | БКИ: Максимальный лимит по кредитному продукту Кредитная карта за все время\n",
      "incomeValue | Значение дохода абонента\n",
      "gender | Пол клиента\n",
      "avg_cur_cr_turn | Средний кредитовый оборот по текущим счетам за 3 месяца\n",
      "adminarea | Регион клиента по geo cross model\n",
      "turn_cur_cr_avg_v2 | Средний кредитовый оборот по текущим счетам за 12 месяцев\n",
      "turn_cur_cr_max_v2 | Максимальный кредитовый оборот по текущим счетам за 12 месяцев\n",
      "hdb_bki_total_pil_max_limit | БКИ: Максимальный лимит по кредитному продукту Кредит за все время\n",
      "age | Возраст клиента\n",
      "dp_ils_avg_salary_1y | данные цифрового профиля\n",
      "turn_cur_cr_sum_v2 | Общий кредитовый оборот по текущим счетам за 12 месяцев\n",
      "by_category__amount__sum__eoperation_type_name__ishodjaschij_bystryj_platezh_sbp | Средняя сумма электронных операций в категории - Исходящий быстрый платеж СБП за месяц на протяжении года\n",
      "turn_cur_db_sum_v2 | Общий дебетовый оборот по текущим счетам за 12 месяцев\n",
      "turn_cur_db_avg_act_v2 | Средний текущий дебетовый оборот по текущим счетам за 12 месяцев\n",
      "dp_ils_avg_salary_2y | данные цифрового профиля\n",
      "curr_rur_amt_cm_avg | Среднее за 12 месяцев среднемесячных остатков на группе счетов Основные текущие счета\n",
      "turn_cur_db_avg_v2 | Средний дебетовый оборот по текущим счетам за 12 месяцев\n",
      "by_category__amount__sum__eoperation_type_name__vhodjaschij_bystryj_platezh_sbp | Средняя сумма электронных операций в категории - Входящий быстрый платеж СБП за месяц на протяжении года\n",
      "dp_ils_paymentssum_avg_6m | данные цифрового профиля\n",
      "avg_cur_db_turn | Средний дебетовый оборот по текущим счетам за 3 месяца\n",
      "hdb_bki_active_cc_max_limit | БКИ: Максимальный лимит по активному кредитному продукту Кредитная карта\n",
      "incomeValueCategory | Категория дохода абонента\n",
      "avg_by_category__amount__sum__cashflowcategory_name__vydacha_nalichnyh_v_bankomate | Средняя сумма транзакций в категории Выдача наличных в банкомате за месяц на протяжении года\n",
      "avg_credit_turn_rur | Средний кредитовый оборот по всем счетам за 3 месяца\n",
      "dp_ils_salary_ratio_1y3y | данные цифрового профиля\n",
      "by_category__amount__sum__eoperation_type_name__perevod_po_nomeru_telefona | Средняя сумма электронных операций в категории - Перевод по номеру телефона за месяц на протяжении года\n",
      "turn_cur_cr_7avg_avg_v2 | Средний кредитовый оборот за последние 7 дней по текущим счетам\n",
      "dp_ils_accpayment_avg_12m | данные цифрового профиля\n",
      "curbal_usd_amt_cm_avg | Средний баланс текущих счетов за последние 3 месяца\n",
      "avg_by_category__amount__sum__cashflowcategory_name__supermarkety | Средняя сумма транзакций в категории Супермаркеты за месяц на протяжении года\n",
      "avg_loan_cnt_with_insurance | Среднее число кредитов наличными со страховкой, начиная с 2018 года\n",
      "avg_by_category__amount__sum__cashflowcategory_name__gipermarkety | Средняя сумма транзакций в категории Гипермаркеты за месяц на протяжении года\n",
      "city_smart_name | Город клиента по методике SMART\n",
      "uniV5 | Скоринг-отчет для банка V5\n",
      "turn_cur_db_max_v2 | Максимальный дебетовый оборот по текущим счетам за 12 месяцев\n",
      "avg_by_category__amount__sum__cashflowcategory_name__kafe | Средняя сумма транзакций в категории Кафе за месяц на протяжении года\n",
      "turn_other_db_max_v2 | Максимальный дебетовый оборот по другим счетам за 12 месяцев\n",
      "turn_cur_cr_min_v2 | Минимальный кредитовый оборот по текущим счетам за 12 месяцев\n",
      "hdb_bki_other_active_pil_outstanding | БКИ: Суммарная задолженность по крединым продуктам Кредит в других банках\n",
      "dp_ewb_last_employment_position | данные цифрового профиля\n",
      "turn_cur_db_min_v2 | Минимальный дебетовый оборот по текущим счетам за 12 месяцев\n",
      "hdb_bki_total_products | БКИ: Число кредитных продуктов, в которых клиент является основным заемщиком\n",
      "per_capita_income_rur_amt | Среднедушевой доход в регионе клиента по Росстату\n",
      "avg_debet_turn_rur | Средний дебетовый оборот по всем счетам за 3 месяца\n",
      "hdb_relend_active_max_psk | БКИ: Максимальная ПСК по активным кредитным продуктам клиента Кредит наличным, Кредитная карта, Микрокредит, Другой\n",
      "dda_rur_amt_curr_v2 | Сумма средств клиента на группе счетов Счета до востребования\n",
      "mob_cnt_days | Количество дней, в которые клиент заходил в Альфа-Мобайл за 90 дней\n",
      "dp_ils_days_from_last_doc | данные цифрового профиля\n",
      "avg_6m_money_transactions | Средние за 6 месяцев траты по группе MCC кодов: Финансовые услуги\n",
      "transaction_category_supermarket_percent_cnt_2m | Доля количества транзакций в категории Супермаркеты от общего количества транзакций за 2 месяца\n",
      "pil | Количество кредитов наличными\n",
      "hdb_bki_total_max_overdue_sum | БКИ: Максимальная сумма просрочки за все время на клиента\n",
      "avg_6m_clothing | Средние за 6 месяцев траты по группе MCC кодов: Одежда\n",
      "avg_by_category__amount__sum__cashflowcategory_name__elektronnye_dengi | Средняя сумма транзакций в категории Электронные деньги за месяц на протяжении года\n",
      "addrref | Регион отделения\n",
      "bki_total_auto_cnt | Количество кредитных продуктов Автокредит за все время\n",
      "dp_payoutincomedata_payout_avg_3_month | данные цифрового профиля\n",
      "hdb_outstand_sum | БКИ: Сумма задолженности\n",
      "avg_3m_money_transactions | Средние за 3 месяца траты по группе MCC кодов: Финансовые услуги\n",
      "dp_address_unique_regions | данные цифрового профиля\n",
      "min_balance_rur_amt_6m_af | Минимальный баланс за последние 6 месяцев по всем фабрикам\n",
      "transaction_category_supermarket_sum_cnt_m3_4 | Количество транзакций в категории Супермаркеты в интервале 3 ... 4 месяцев\n",
      "dp_payoutincomedata_payout_max_3_month | данные цифрового профиля\n",
      "hdb_bki_total_ip_max_limit | БКИ: Максимальный лимит по кредитному продукту Ипотека за все время\n",
      "hdb_bki_total_cnt | БКИ: Число обращений в БКИ по клиенту\n",
      "blacklist_flag | Флаг черного списка\n",
      "bki_total_oth_cnt | Количество кредитных продуктов Другой за все время\n",
      "dp_payoutincomedata_payout_sum_3_month | данные цифрового профиля\n",
      "hdb_relend_outstand_sum | БКИ: Сумма задолженности по продуктам Кредит наличным, Кредитная карта, Микрокредит, Другой\n",
      "total_rur_amt_cm_avg | Среднее за 12 месяцев среднемесячных остатков на группе счетов Собственные средства\n",
      "mob_cover_days | Количество дней, в течение которых клиент заходил в Альфа-Мобайле, поделенные на период 90 дней\n",
      "dp_payoutincomedata_payout_max_6_month | данные цифрового профиля\n",
      "label_Below_50k_share_r1 | внешние данные\n",
      "turn_fdep_db_sum_v2 | Общий дебетовый оборот по депозитным счетам за 12 месяцев\n",
      "dp_ils_accpayment_avg_6m_current | данные цифрового профиля\n",
      "transaction_category_cash_percent_amt_2m | Доля суммы транзакций в категории Cash от общей суммы транзакций за 2 месяца\n",
      "curr_rur_amt_3m_avg | Среднее за 3 месяца среднемесячных остатков на группе счетов Основные текущие счета\n",
      "transaction_category_restaurants_sum_amt_m2 | Сумма транзакций в категории Рестораны за 2 месяца\n",
      "loan_cnt | Число кредитов наличными у клиента, начиная с 2018 года\n",
      "turn_fdep_db_avg_v2 | Средний дебетовый оборот по депозитным счетам за 12 месяцев\n",
      "turn_cur_db_7avg_avg_v2 | Средний дебетовый оборот за последние 7 дней по текущим счетам\n",
      "bki_total_ip_max_outstand | Максимальная задолженность по кредитному продукту Ипотека\n",
      "amount_by_category_90d__summarur_amt__sum__cashflowcategory_name__vydacha_nalichnyh_v_bankomate | Сумма транзакций за 90 дней в категории Выдача наличных в банкомате\n",
      "profit_income_out_rur_amt_12m | Средний операционный доход за 12 месяцев до даты расчета\n",
      "avg_6m_hotels | Средние за 6 месяцев траты по группе MCC кодов: Отели\n",
      "hdb_ovrd_sum | БКИ: Сумма просрочки\n",
      "dp_ils_total_seniority | данные цифрового профиля\n",
      "dp_ils_paymentssum_avg_6m_current | данные цифрового профиля\n",
      "smsInWavg6m | Средневзвешенное значение “среднемесячного кол-ва входящих сообщений абонентов Компании за 6 месяцев, включая отчетный” по группе общения\n",
      "avg_fdep_db_turn | Средний дебетовый оборот по депозитным счетам за 3 месяца\n",
      "device_iphone_avg | Доля сессий в Альфа-Мобайле с устройства iphone за период 90 дней\n",
      "by_category__amount__sum__eoperation_type_name__platezh_za_mobilnyj_cherez_ps | Средняя сумма электронных операций в категории - Платёж за мобильный через ПС за месяц на протяжении года\n",
      "avg_balance_rur_amt_1m_af | Средний баланс за последний месяц по всем фабрикам\n",
      "curr_rur_amt_cm_avg_period_days_ago_v2 | Средняя сумма средств клиента на группе счетов Основные текущие счета за 2 месяца до даты расчета\n",
      "avg_by_category__amount__sum__cashflowcategory_name__oteli | Средняя сумма транзакций в категории Отели за месяц на протяжении года\n",
      "hdb_bki_total_ip_cnt | БКИ: Количество кредитных продуктов Ипотека за все время\n",
      "hdb_bki_active_cc_max_outstand | БКИ: Максимальная текущая задолженность по кредитному продукту Кредитная карта\n",
      "hdb_other_outstand_sum | БКИ: Сумма задолженности по крединым продуктам в других банках\n",
      "days_to_last_transaction | Количество дней до последней транзакции\n",
      "hdb_bki_total_pil_max_overdue | БКИ: Максимальная просрочка по кредитному продукту Кредит за все время\n",
      "vert_pil_last_credit_step_screen_view_3m | Количество событий вида 'Last Credit Step Screen View' за 3 месяца\n",
      "acard | Количество Альфа-карт\n",
      "bki_total_il_max_limit | Максимальный лимит по кредитному продукту Кредит\n",
      "other_credits_count | Количество кредитных продуктов в других банках\n",
      "tz_msk_timedelta | Таймзона относительно Москвы\n",
      "turn_save_db_min_v2 | Минимальный дебетовый оборот по накопительным счетам за 12 месяцев\n",
      "profit_income_out_rur_amt_9m | Средний операционный доход за 9 месяцев до даты расчета\n",
      "dp_ils_ipkcurrentyear_currentyearpensfactor | данные цифрового профиля\n",
      "avg_by_category__amount__sum__cashflowcategory_name__odezhda | Средняя сумма транзакций в категории Одежда за месяц на протяжении года\n",
      "cntOnnRinCallAvg6m | Среднемесячное количество входящих звонков во внутрисетевом роуминге за 6 месяцев (включая отчетный месяц)\n",
      "dda_rur_amt_3m_avg | Среднее за 3 месяца среднемесячных остатков на группе счетов Счета до востребования\n",
      "winback_cnt | Количество раз возвращений в WinBack (возвращения клиента из состоятния оттока)\n",
      "salary_median_in_gex_r1 | гео данные\n",
      "dp_payoutincomedata_payout_avg_prev_year | данные цифрового профиля\n",
      "avg_amount_daily_transactions_90d | Средняя дневная сумма транзакций за 90 дней\n",
      "vert_has_app_ru_tinkoff_investing | Наличие у клиента приложения Тинькоф Инвестиции\n",
      "transaction_category_supermarket_inc_cnt_2m | Количество транзакций в категории Супермаркеты за последние 2 месяца поделённое на среднее Количество транзакций в этой категории за 2 месяца (на протяжении года)\n",
      "vert_pil_sms_success_3m | Количество событий вида 'Sms Success' за 3 месяца\n",
      "min_balance_rur_amt_1m_af | Минимальный баланс за последний месяц по всем фабрикам\n",
      "dp_ils_max_seniority | данные цифрового профиля\n",
      "avg_by_category__amount__sum__cashflowcategory_name__set_supermarketov | Средняя сумма транзакций в категории Сеть супермаркетов за месяц на протяжении года\n",
      "label_500k_to_1M_share_r1 | внешние данные\n",
      "avg_by_category__amount__sum__cashflowcategory_name__zarubezhnye_finansovye_operatsii | Средняя сумма транзакций в категории Зарубежные финансовые операции за месяц на протяжении года\n",
      "bki_total_products | Количество кредитных продуктов за все время на клиента\n",
      "avg_6m_all | Средние за 6 месяцев траты по всем группам MCC кодов\n",
      "dp_ils_avg_simultanious_jobs_5y | данные цифрового профиля\n",
      "dp_ewb_dismissal_due_contract_violation_by_lb_cnt | данные цифрового профиля\n",
      "summarur_1m_purch | Сумма покупок в текущем месяце\n",
      "diff_avg_cr_db_turn | Разница между средним кредитовым и дебетовым оборотом по счетам за 3 месяца\n",
      "dp_ils_cnt_changes_1y | данные цифрового профиля\n",
      "dp_ils_employeers_cnt_last_month | данные цифрового профиля\n",
      "dp_payoutincomedata_payout_avg_6_month | данные цифрового профиля\n",
      "dp_ewb_last_organization | данные цифрового профиля\n",
      "by_category__amount__sum__eoperation_type_name__perevod_mezhdu_svoimi_schetami | Средняя сумма электронных операций в категории - Перевод между своими счетами за месяц на протяжении года\n",
      "bki_active_auto_cnt | Количество активных кредитных продуктов Автокредит\n",
      "turn_other_cr_avg_act_v2 | Средний текущий кредитовый оборот по другим счетам за 12 месяцев\n",
      "cntVoiceOutMob6m | Среднее значение “среднемесячного кол-ва исходящих звонков (onnet+offnet) абонента Компании за 6 месяцев, включая отчетный” по группе общения\n",
      "avg_by_category__amount__sum__cashflowcategory_name__puteshestvija | Средняя сумма транзакций в категории Путешествия за месяц на протяжении года\n",
      "loanacc_rur_amt_cm_avg | Среднее за 12 месяцев среднемесячных остатков на группе счетов Кредитные счета\n",
      "transaction_category_supermarket_sum_cnt_m2 | Количество транзакций в категории Супермаркеты за 2 месяца\n",
      "transaction_category_supermarket_sum_amt_d15 | Сумма транзакций в категории Супермаркеты за 15 дней\n",
      "avg_fdep_cr_turn | Средний кредитовый оборот по депозитным счетам за 3 месяца\n",
      "transaction_category_restaurants_percent_cnt_2m | Доля количества транзакций в категории Рестораны от общего количества транзакций за 2 месяца\n",
      "bki_total_max_limit | Максимальный кредитный лимит по любому продукту за все время\n",
      "avg_by_category__amount__sum__cashflowcategory_name__reklama_v_internete | Средняя сумма транзакций в категории Реклама в интернете за месяц на протяжении года\n",
      "transaction_category_restaurants_percent_amt_2m | Доля суммы транзакций в категории Рестораны от общей суммы транзакций за 2 месяца\n",
      "turn_fdep_db_avg_act_v2 | Средний текущий дебетовый оборот по депозитным счетам за 12 месяцев\n",
      "dp_ils_accpayment_avg_6m | данные цифрового профиля\n",
      "turn_other_cr_sum_v2 | Общий кредитовый оборот по другим счетам за 12 месяцев\n",
      "client_active_flag | Флаг активности клиента\n",
      "avg_by_category__amount__sum__cashflowcategory_name__produkty | Средняя сумма транзакций в категории Продукты за месяц на протяжении года\n",
      "curr_rur_amt_cm_avg_inc_v2 | Разница средней суммы на Основных текущих счетах за текущий месяц на начало и конец 2х-месячного периода\n",
      "nonresident_flag | Признак нерезидента РФ\n",
      "avg_by_category__amount__sum__cashflowcategory_name__kosmetika | Средняя сумма транзакций в категории Косметика за месяц на протяжении года\n",
      "vert_has_app_ru_vtb_invest | Наличие у клиента приложения ВТБ Инвестиции\n",
      "dp_ils_avg_salary_3y | данные цифрового профиля\n",
      "hdb_bki_total_auto_max_limit | БКИ: Максимальный лимит по кредитному продукту Автокредит за все время\n",
      "days_after_last_request | Количество дней между датой расчета и event time - времени запроса к Beeline\n",
      "cntRegionTripsWavg1m | Средневзвешенное значение “кол-ва поездок в регионы России (не в Москву) абонента Компании” по группе общения за отчетный месяц\n",
      "vert_has_app_ru_cian_main | Наличие у клиента приложения ЦИАН\n",
      "loanacc_rur_amt_curr_v2 | Сумма средств клиента на группе счетов Кредитные счета\n",
      "avg_3m_no_cat | Средние за 3 месяца траты по группе MCC кодов: Без категории\n",
      "vert_ghost_close_dpay3_last_days | Количество дней до последнего закрытия продукта призрака с темой 'Daily Pay'\n",
      "vert_has_app_ru_raiffeisennews | Наличие у клиента приложения Раффайзенбанка\n",
      "dp_ils_days_ip_share_5y | данные цифрового профиля\n",
      "avg_by_category__amount__sum__cashflowcategory_name__platezhi_cherez_internet | Средняя сумма транзакций в категории Платежи через интернет за месяц на протяжении года\n",
      "hdb_bki_total_micro_max_overdue | БКИ: Максимальная просрочка по кредитному продукту Микрокредит за все время\n",
      "bki_total_active_products | Количество активных кредитных продуктов на клиента\n",
      "by_category__amount__sum__eoperation_type_name__perevod_s_karty_na_kartu | Средняя сумма электронных операций в категории - Перевод с карты на карту за месяц на протяжении года\n",
      "calledCtnOutGroup | Размер группы общения по новому алгоритму при исходящих звонках/смс\n",
      "vert_pil_loan_application_success_3m | Количество событий вида 'Loan Application Success' за 3 месяца\n",
      "vert_pil_fee_discount_change_3m | Количество событий вида 'Fee Discount Change' за 3 месяца\n",
      "businessTelSubs | Кол-во абонентов из группы общения, имеющих значение «Business» в показателе «Класс устройства» (CLASS) на дату заявки\n",
      "profit_income_out_rur_amt_l2m | Операционный доход Profit3 (на месяц T-4) где Т -- месяц оттока\n",
      "avg_3m_healthcare_services | Средние за 3 месяца траты по группе MCC кодов: Медицинские услуги\n",
      "dp_ils_paymentssum_month_avg | данные цифрового профиля\n",
      "ovrd_sum | Сумма просрочки\n",
      "hdb_bki_total_active_products | БКИ: Количество активных кредитных продуктов на клиента\n",
      "hdb_bki_total_micro_cnt | БКИ: Количество кредитных продуктов Микрокредит за все время\n",
      "hdb_bki_active_pil_cnt | БКИ: Количество активных кредитных продуктов Кредит\n",
      "loan_cur_amt | Сумма запрашиваемого кредита\n",
      "mob_total_sessions | Количество сессий в Альфа-Мобайле за период 90 дней\n",
      "period_last_act_ad | Год-месяц последней активности в АД на текущую дату\n",
      "dp_ils_days_multiple_job_share_2y | данные цифрового профиля\n",
      "hdb_bki_total_cc_max_overdue | БКИ: Максимальная просрочка по кредитному продукту Кредитная карта за все время\n",
      "lifetimeComp | Время жизни абонента конкурента (с момента первого появления до даты заявки)\n",
      "hdb_bki_total_pil_last_days | БКИ: Количество дней с последнего оформленного кредитного продукта Кредит\n",
      "amount_by_category_90d__summarur_amt__sum__cashflowcategory_name__elektronnye_dengi | Сумма транзакций за 90 дней в категории Электронные деньги\n",
      "turn_save_cr_max_v2 | Максимальный кредитовый оборот по накопительным счетам за 12 месяцев\n",
      "hdb_bki_active_pil_max_limit | БКИ: Максимальный лимит по активному кредитному продукту Кредит\n",
      "dp_ils_accpayment_avg_3m | данные цифрового профиля\n",
      "avg_6m_restaurants | Средние за 6 месяцев траты по группе MCC кодов: Рестораны, фастфуд\n",
      "hdb_bki_total_pil_cnt | БКИ: Количество кредитных продуктов Кредит за все время\n",
      "transaction_category_fastfood_percent_cnt_2m | Доля количества транзакций в категории Фаст Фуд от общего количества транзакций за 2 месяца\n",
      "hdb_bki_total_pil_max_del90 | БКИ: Количество просрочек свыше 90 дней по кредитному продукту Кредит за все время\n",
      "accountsalary_out_flag | Признак наличия зарплатного счета у клиента на момент последней активности\n",
      "cntBlockWavg6m | Средневзвешенное среднемесячное количество блокировок любого типа за 6 месяцев\n",
      "express_rur_amt_cm_avg | Среднее за 12 месяцев среднемесячных остатков на группе счетов Экспресс счета\n",
      "loanacc_rur_amt_cm_avg_inc_v2 | Разница средней суммы на Кредитных счетах за текущий месяц на начало и конец 2х-месячного периода\n",
      "hdb_bki_last_product_days | БКИ: Количество дней с оформления последнего кредитного продукта\n",
      "dp_ils_days_multiple_job_cnt_5y | данные цифрового профиля\n",
      "dp_ils_accpayment_month_avg | данные цифрового профиля\n",
      "cred_dda_rur_amt_3m_avg | Среднее за 3 месяца среднемесячных остатков на группе счетов Текущие счета кредитов\n",
      "avg_3m_all | Средние за 3 месяца траты по всем группам MCC кодов\n",
      "hdb_other_active_max_psk | БКИ: Максимальная ПСК по активным кредитным продуктам в других банках\n",
      "hdb_bki_other_active_ip_outstanding | БКИ: Суммарная задолженность по крединым продуктам Ипотека в других банках\n",
      "total_sum | Общая сумма просрочки за весь период нахождения в банке\n",
      "dp_ils_uniq_companies_1y | данные цифрового профиля\n",
      "avg_6m_travel | Средние за 6 месяцев траты по группе MCC кодов: Турагентства\n",
      "avg_6m_government_services | Средние за 6 месяцев траты по группе MCC кодов: Платежи в бюджет\n",
      "hdb_bki_active_cc_max_overdue | БКИ: Максимальная текущая просрочка по активному кредитному продукту Кредитная карта\n",
      "total_rur_amt_cm_avg_period_days_ago_v2 | Средняя сумма средств клиента на группе счетов Собственные средства за 2 месяца до даты расчета\n",
      "label_Above_1M_share_r1 | внешние данные\n",
      "transaction_category_supermarket_sum_cnt_d15 | Количество транзакций в категории Супермаркеты за 15 дней\n",
      "max_balance_rur_amt_1m_af | Максимальный баланс за последний месяц по всем фабрикам\n",
      "id | id клиента\n",
      "w | вес\n",
      "first_salary_income | внешние данные\n"
     ]
    }
   ],
   "source": [
    "for i in range(features.shape[0]):\n",
    "    print(features.iloc[i,0], '|', features.iloc[i,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "921897ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan,  1.])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['vert_has_app_ru_tinkoff_investing'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a57c3",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5dabc",
   "metadata": {},
   "source": [
    "## Filling NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "6765a760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6938526\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isna().sum().sum())\n",
    "cleaned_data = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "156612bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = test_df.select_dtypes(exclude=['datetime64[ns]', 'object', 'category']).columns\n",
    "cleaned_data[num_cols] = cleaned_data[num_cols].fillna(0)\n",
    "test_df[num_cols] = test_df[num_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "4c768785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60971185",
   "metadata": {},
   "source": [
    "# Model train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "561b78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric define\n",
    "def weighted_mean_absolute_error(y_true, y_pred, weights):\n",
    "    return (weights * np.abs(y_true - y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_data.drop(columns=['id', 'dt', 'target', 'w'])\n",
    "object_col = X.select_dtypes(include=['object']).columns\n",
    "X[object_col] = X[object_col].astype('category')\n",
    "w = cleaned_data['w']\n",
    "y = cleaned_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "af256844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.78135971352466)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86345532",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25eb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 150, 2000),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 7, 9),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 23\n",
    "    }\n",
    "    \n",
    "    model = lightgbm.LGBMRegressor(**params, max_bin=1000)\n",
    "\n",
    "    splitter = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "\n",
    "    # y_log = np.log1p(y)\n",
    "\n",
    "    wmean_mae = []\n",
    "\n",
    "    for _, (train_index, valid_index) in enumerate(splitter.split(X, y)):\n",
    "\n",
    "        X_train , y_train, w_train = X.iloc[train_index], y.iloc[train_index], w.iloc[train_index]\n",
    "        X_valid, y_valid, w_valid = X.iloc[valid_index], y.iloc[valid_index], w.iloc[valid_index]\n",
    "\n",
    "        model.fit(X_train, y_train, sample_weight=w_train,\n",
    "                eval_metric='mae', eval_set=[(X_valid, y_valid)],\n",
    "                    callbacks=[lightgbm.early_stopping(50), lightgbm.log_evaluation(period=0)])\n",
    "        \n",
    "        y_pred = model.predict(X_valid)\n",
    "        wmean_mae.append(weighted_mean_absolute_error(y_valid, y_pred, w_valid)) #np.expm1(y_valid), np.expm1(y_pred)\n",
    "    \n",
    "    return np.mean(wmean_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "97389ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 08:29:33,152] A new study created in memory with name: lgbm_opt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d8d069ab48412aa4ad4b265889175d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's l1: 0.403946\tvalid_0's l2: 0.285087\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's l1: 0.405809\tvalid_0's l2: 0.287503\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 0.405681\tvalid_0's l2: 0.287528\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l1: 0.400468\tvalid_0's l2: 0.278511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's l1: 0.403666\tvalid_0's l2: 0.286341\n",
      "[I 2025-11-30 08:29:56,679] Trial 0 finished with value: 38673.2273016315 and parameters: {'n_estimators': 1859, 'max_depth': 9, 'num_leaves': 34, 'learning_rate': 0.27108307260485426, 'subsample': 0.763851976082019, 'colsample_bytree': 0.9212653493967059, 'reg_alpha': 9.989089541901258, 'reg_lambda': 0.1551056215412509}. Best is trial 0 with value: 38673.2273016315.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1777]\tvalid_0's l1: 0.379699\tvalid_0's l2: 0.260427\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1875]\tvalid_0's l1: 0.381822\tvalid_0's l2: 0.261812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1875]\tvalid_0's l1: 0.379283\tvalid_0's l2: 0.258789\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1856]\tvalid_0's l1: 0.375863\tvalid_0's l2: 0.250875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1871]\tvalid_0's l1: 0.378216\tvalid_0's l2: 0.258546\n",
      "[I 2025-11-30 08:33:45,054] Trial 1 finished with value: 37531.085229624514 and parameters: {'n_estimators': 1875, 'max_depth': 9, 'num_leaves': 41, 'learning_rate': 0.02686201779459857, 'subsample': 0.6202074885021398, 'colsample_bytree': 0.8893998759424161, 'reg_alpha': 0.047583523937520224, 'reg_lambda': 0.024177430831929986}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[849]\tvalid_0's l1: 0.394083\tvalid_0's l2: 0.271989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[849]\tvalid_0's l1: 0.396181\tvalid_0's l2: 0.274151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[847]\tvalid_0's l1: 0.392387\tvalid_0's l2: 0.271552\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[849]\tvalid_0's l1: 0.390149\tvalid_0's l2: 0.263802\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[849]\tvalid_0's l1: 0.39378\tvalid_0's l2: 0.272129\n",
      "[I 2025-11-30 08:35:17,822] Trial 2 finished with value: 37736.669041135116 and parameters: {'n_estimators': 849, 'max_depth': 8, 'num_leaves': 30, 'learning_rate': 0.013524325305712822, 'subsample': 0.6128476596013792, 'colsample_bytree': 0.5373444603020494, 'reg_alpha': 0.004672345093689042, 'reg_lambda': 0.0037135027472201005}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's l1: 0.398868\tvalid_0's l2: 0.279788\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's l1: 0.398979\tvalid_0's l2: 0.280994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's l1: 0.397154\tvalid_0's l2: 0.277822\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's l1: 0.39577\tvalid_0's l2: 0.271467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's l1: 0.399562\tvalid_0's l2: 0.280709\n",
      "[I 2025-11-30 08:37:40,258] Trial 3 finished with value: 38492.02158145736 and parameters: {'n_estimators': 1964, 'max_depth': 9, 'num_leaves': 39, 'learning_rate': 0.20403674352764833, 'subsample': 0.8598260483789266, 'colsample_bytree': 0.8230121199274233, 'reg_alpha': 0.0011395430490137803, 'reg_lambda': 0.3506368277530807}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l1: 0.408462\tvalid_0's l2: 0.290247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 0.406635\tvalid_0's l2: 0.288977\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 0.404184\tvalid_0's l2: 0.286552\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's l1: 0.401963\tvalid_0's l2: 0.280035\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's l1: 0.409206\tvalid_0's l2: 0.291736\n",
      "[I 2025-11-30 08:37:56,157] Trial 4 finished with value: 39085.5057259909 and parameters: {'n_estimators': 1632, 'max_depth': 9, 'num_leaves': 37, 'learning_rate': 0.2960585624044084, 'subsample': 0.5237432139099311, 'colsample_bytree': 0.6493736787668771, 'reg_alpha': 0.08092257910359055, 'reg_lambda': 0.04486109756866822}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l1: 0.401532\tvalid_0's l2: 0.283286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's l1: 0.403081\tvalid_0's l2: 0.285579\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's l1: 0.398214\tvalid_0's l2: 0.281186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 0.397176\tvalid_0's l2: 0.275212\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's l1: 0.401019\tvalid_0's l2: 0.282204\n",
      "[I 2025-11-30 08:38:19,080] Trial 5 finished with value: 38953.692575567504 and parameters: {'n_estimators': 1952, 'max_depth': 8, 'num_leaves': 46, 'learning_rate': 0.23803026911496558, 'subsample': 0.5536949031697584, 'colsample_bytree': 0.9518720520213517, 'reg_alpha': 0.0011451454361558827, 'reg_lambda': 0.006226771838928462}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[768]\tvalid_0's l1: 0.388444\tvalid_0's l2: 0.269068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[749]\tvalid_0's l1: 0.390027\tvalid_0's l2: 0.269604\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[768]\tvalid_0's l1: 0.386963\tvalid_0's l2: 0.266602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[767]\tvalid_0's l1: 0.383997\tvalid_0's l2: 0.25779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[759]\tvalid_0's l1: 0.388084\tvalid_0's l2: 0.26784\n",
      "[I 2025-11-30 08:39:19,244] Trial 6 finished with value: 38013.62268682094 and parameters: {'n_estimators': 768, 'max_depth': 7, 'num_leaves': 22, 'learning_rate': 0.05393945086551159, 'subsample': 0.8424842073373756, 'colsample_bytree': 0.7515248545982436, 'reg_alpha': 0.002710170322535546, 'reg_lambda': 0.07862177072910222}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1189]\tvalid_0's l1: 0.383634\tvalid_0's l2: 0.264058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[956]\tvalid_0's l1: 0.385977\tvalid_0's l2: 0.266403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1155]\tvalid_0's l1: 0.38326\tvalid_0's l2: 0.262278\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[919]\tvalid_0's l1: 0.380962\tvalid_0's l2: 0.257219\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1039]\tvalid_0's l1: 0.382369\tvalid_0's l2: 0.262852\n",
      "[I 2025-11-30 08:41:28,122] Trial 7 finished with value: 37765.18120654844 and parameters: {'n_estimators': 1189, 'max_depth': 9, 'num_leaves': 34, 'learning_rate': 0.054182132526064845, 'subsample': 0.8840304598407627, 'colsample_bytree': 0.9972534474694412, 'reg_alpha': 0.002689078248673233, 'reg_lambda': 7.660103408279273}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 0.409084\tvalid_0's l2: 0.29033\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's l1: 0.406705\tvalid_0's l2: 0.287894\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's l1: 0.405016\tvalid_0's l2: 0.286018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l1: 0.400625\tvalid_0's l2: 0.276171\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's l1: 0.407705\tvalid_0's l2: 0.287916\n",
      "[I 2025-11-30 08:41:46,408] Trial 8 finished with value: 39435.820688497086 and parameters: {'n_estimators': 1030, 'max_depth': 8, 'num_leaves': 19, 'learning_rate': 0.29070747441732614, 'subsample': 0.9842199974612966, 'colsample_bytree': 0.5910492036110268, 'reg_alpha': 0.00512920416988412, 'reg_lambda': 9.468869923318724}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[690]\tvalid_0's l1: 0.385438\tvalid_0's l2: 0.265714\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[603]\tvalid_0's l1: 0.387451\tvalid_0's l2: 0.267335\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[562]\tvalid_0's l1: 0.385561\tvalid_0's l2: 0.265539\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[521]\tvalid_0's l1: 0.383348\tvalid_0's l2: 0.259252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[689]\tvalid_0's l1: 0.385852\tvalid_0's l2: 0.266384\n",
      "[I 2025-11-30 08:42:45,689] Trial 9 finished with value: 37931.05045188501 and parameters: {'n_estimators': 690, 'max_depth': 7, 'num_leaves': 30, 'learning_rate': 0.09134832620382102, 'subsample': 0.9842184455581917, 'colsample_bytree': 0.7626424893016028, 'reg_alpha': 0.0010295834076430406, 'reg_lambda': 0.06608066849994972}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid_0's l1: 0.388565\tvalid_0's l2: 0.269806\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[389]\tvalid_0's l1: 0.388521\tvalid_0's l2: 0.268651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[492]\tvalid_0's l1: 0.386418\tvalid_0's l2: 0.267581\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's l1: 0.385274\tvalid_0's l2: 0.261326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[362]\tvalid_0's l1: 0.388279\tvalid_0's l2: 0.26796\n",
      "[I 2025-11-30 08:43:47,484] Trial 10 finished with value: 38218.71914065222 and parameters: {'n_estimators': 1405, 'max_depth': 9, 'num_leaves': 49, 'learning_rate': 0.13095011757914207, 'subsample': 0.6643429101295212, 'colsample_bytree': 0.8686432139619715, 'reg_alpha': 0.13720220314054069, 'reg_lambda': 1.0144122961855355}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\tvalid_0's l1: 0.408278\tvalid_0's l2: 0.2855\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l1: 0.411027\tvalid_0's l2: 0.289425\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l1: 0.407317\tvalid_0's l2: 0.286615\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l1: 0.403514\tvalid_0's l2: 0.27893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l1: 0.409602\tvalid_0's l2: 0.28747\n",
      "[I 2025-11-30 08:44:35,905] Trial 11 finished with value: 40099.459482453785 and parameters: {'n_estimators': 400, 'max_depth': 8, 'num_leaves': 26, 'learning_rate': 0.010009938943820018, 'subsample': 0.6358060606336245, 'colsample_bytree': 0.5022333314674922, 'reg_alpha': 0.03124432887214805, 'reg_lambda': 0.0011865661953340445}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[227]\tvalid_0's l1: 0.401388\tvalid_0's l2: 0.279407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[229]\tvalid_0's l1: 0.402929\tvalid_0's l2: 0.282291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[230]\tvalid_0's l1: 0.399937\tvalid_0's l2: 0.279812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[230]\tvalid_0's l1: 0.39607\tvalid_0's l2: 0.272162\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[230]\tvalid_0's l1: 0.401422\tvalid_0's l2: 0.280259\n",
      "[I 2025-11-30 08:45:12,006] Trial 12 finished with value: 39239.317347644734 and parameters: {'n_estimators': 230, 'max_depth': 8, 'num_leaves': 44, 'learning_rate': 0.015966714376452102, 'subsample': 0.6343373421823771, 'colsample_bytree': 0.6580110973070897, 'reg_alpha': 0.01574795455123012, 'reg_lambda': 0.009297231088284123}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[428]\tvalid_0's l1: 0.395144\tvalid_0's l2: 0.274478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's l1: 0.396468\tvalid_0's l2: 0.275568\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[749]\tvalid_0's l1: 0.39147\tvalid_0's l2: 0.271238\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[407]\tvalid_0's l1: 0.390491\tvalid_0's l2: 0.264686\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[670]\tvalid_0's l1: 0.391385\tvalid_0's l2: 0.271179\n",
      "[I 2025-11-30 08:45:57,230] Trial 13 finished with value: 38685.67578989982 and parameters: {'n_estimators': 887, 'max_depth': 7, 'num_leaves': 15, 'learning_rate': 0.14689878872248072, 'subsample': 0.710270275776594, 'colsample_bytree': 0.5003242378414302, 'reg_alpha': 0.5768276276969865, 'reg_lambda': 0.0063436577976832935}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[492]\tvalid_0's l1: 0.385233\tvalid_0's l2: 0.265055\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[792]\tvalid_0's l1: 0.384748\tvalid_0's l2: 0.265589\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[403]\tvalid_0's l1: 0.385053\tvalid_0's l2: 0.265161\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[590]\tvalid_0's l1: 0.380283\tvalid_0's l2: 0.255836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[677]\tvalid_0's l1: 0.38234\tvalid_0's l2: 0.262443\n",
      "[I 2025-11-30 08:47:15,614] Trial 14 finished with value: 37935.00639140351 and parameters: {'n_estimators': 1336, 'max_depth': 8, 'num_leaves': 41, 'learning_rate': 0.08442718863049745, 'subsample': 0.5868762378022437, 'colsample_bytree': 0.831899387429041, 'reg_alpha': 0.33755034025561337, 'reg_lambda': 0.0013177258431157327}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's l1: 0.396738\tvalid_0's l2: 0.277027\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's l1: 0.397195\tvalid_0's l2: 0.277447\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's l1: 0.396768\tvalid_0's l2: 0.278094\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid_0's l1: 0.393322\tvalid_0's l2: 0.270018\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's l1: 0.396083\tvalid_0's l2: 0.27757\n",
      "[I 2025-11-30 08:47:44,611] Trial 15 finished with value: 38833.198360288436 and parameters: {'n_estimators': 496, 'max_depth': 8, 'num_leaves': 29, 'learning_rate': 0.18613176090563346, 'subsample': 0.755527023333282, 'colsample_bytree': 0.6900381533410831, 'reg_alpha': 0.013169321851408514, 'reg_lambda': 0.017013329945096394}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1452]\tvalid_0's l1: 0.381057\tvalid_0's l2: 0.26047\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1569]\tvalid_0's l1: 0.383225\tvalid_0's l2: 0.262228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1429]\tvalid_0's l1: 0.380926\tvalid_0's l2: 0.260687\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1434]\tvalid_0's l1: 0.377803\tvalid_0's l2: 0.252601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1033]\tvalid_0's l1: 0.3824\tvalid_0's l2: 0.261765\n",
      "[I 2025-11-30 08:49:50,243] Trial 16 finished with value: 37721.40448298561 and parameters: {'n_estimators': 1586, 'max_depth': 9, 'num_leaves': 27, 'learning_rate': 0.049457790082225776, 'subsample': 0.582680874630025, 'colsample_bytree': 0.6094930074510371, 'reg_alpha': 1.572718810190375, 'reg_lambda': 0.02250424795376943}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[863]\tvalid_0's l1: 0.386166\tvalid_0's l2: 0.265885\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[638]\tvalid_0's l1: 0.390909\tvalid_0's l2: 0.270037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[741]\tvalid_0's l1: 0.387005\tvalid_0's l2: 0.266282\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\tvalid_0's l1: 0.3845\tvalid_0's l2: 0.2601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[581]\tvalid_0's l1: 0.388084\tvalid_0's l2: 0.26664\n",
      "[I 2025-11-30 08:52:21,730] Trial 17 finished with value: 38080.82614689095 and parameters: {'n_estimators': 1651, 'max_depth': 9, 'num_leaves': 22, 'learning_rate': 0.10264350678836881, 'subsample': 0.512544768014607, 'colsample_bytree': 0.5858108597985555, 'reg_alpha': 3.3095170105467155, 'reg_lambda': 0.023903671531974785}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1063]\tvalid_0's l1: 0.379495\tvalid_0's l2: 0.259504\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1665]\tvalid_0's l1: 0.379013\tvalid_0's l2: 0.257703\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1061]\tvalid_0's l1: 0.379596\tvalid_0's l2: 0.259735\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1315]\tvalid_0's l1: 0.374671\tvalid_0's l2: 0.251114\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1328]\tvalid_0's l1: 0.377592\tvalid_0's l2: 0.256686\n",
      "[I 2025-11-30 08:54:54,518] Trial 18 finished with value: 37759.26013036987 and parameters: {'n_estimators': 1672, 'max_depth': 9, 'num_leaves': 42, 'learning_rate': 0.05526375231908294, 'subsample': 0.7001274035151276, 'colsample_bytree': 0.7045625318434247, 'reg_alpha': 0.8334421071192716, 'reg_lambda': 0.3157104556405345}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[624]\tvalid_0's l1: 0.385678\tvalid_0's l2: 0.265851\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[450]\tvalid_0's l1: 0.387995\tvalid_0's l2: 0.2689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[455]\tvalid_0's l1: 0.386345\tvalid_0's l2: 0.265505\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[367]\tvalid_0's l1: 0.383656\tvalid_0's l2: 0.258837\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's l1: 0.387606\tvalid_0's l2: 0.267476\n",
      "[I 2025-11-30 08:55:52,455] Trial 19 finished with value: 38033.78778266268 and parameters: {'n_estimators': 1466, 'max_depth': 9, 'num_leaves': 36, 'learning_rate': 0.11441392971140002, 'subsample': 0.5701128479314449, 'colsample_bytree': 0.7969446522123007, 'reg_alpha': 1.5391456810459527, 'reg_lambda': 0.02451139708195426}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1682]\tvalid_0's l1: 0.38283\tvalid_0's l2: 0.262911\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1600]\tvalid_0's l1: 0.38481\tvalid_0's l2: 0.264204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1667]\tvalid_0's l1: 0.382589\tvalid_0's l2: 0.261964\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1039]\tvalid_0's l1: 0.382419\tvalid_0's l2: 0.257284\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1684]\tvalid_0's l1: 0.382594\tvalid_0's l2: 0.262476\n",
      "[I 2025-11-30 08:58:11,897] Trial 20 finished with value: 37964.65966221449 and parameters: {'n_estimators': 1684, 'max_depth': 9, 'num_leaves': 25, 'learning_rate': 0.045988945618639775, 'subsample': 0.6897749673612762, 'colsample_bytree': 0.8860832935307468, 'reg_alpha': 0.14471442654946604, 'reg_lambda': 0.002769090976516956}. Best is trial 1 with value: 37531.085229624514.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1107]\tvalid_0's l1: 0.382014\tvalid_0's l2: 0.261903\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1107]\tvalid_0's l1: 0.384593\tvalid_0's l2: 0.264419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1103]\tvalid_0's l1: 0.382458\tvalid_0's l2: 0.262145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1107]\tvalid_0's l1: 0.380088\tvalid_0's l2: 0.255106\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1107]\tvalid_0's l1: 0.382379\tvalid_0's l2: 0.261706\n",
      "[I 2025-11-30 09:00:14,544] Trial 21 finished with value: 37483.52336874395 and parameters: {'n_estimators': 1107, 'max_depth': 8, 'num_leaves': 30, 'learning_rate': 0.030311297266514957, 'subsample': 0.6027291341827584, 'colsample_bytree': 0.5665834887178675, 'reg_alpha': 0.03020759761836678, 'reg_lambda': 0.0026265589097170276}. Best is trial 21 with value: 37483.52336874395.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1192]\tvalid_0's l1: 0.382026\tvalid_0's l2: 0.262422\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[766]\tvalid_0's l1: 0.38739\tvalid_0's l2: 0.267423\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's l1: 0.38368\tvalid_0's l2: 0.263343\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1008]\tvalid_0's l1: 0.381454\tvalid_0's l2: 0.256474\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[759]\tvalid_0's l1: 0.383187\tvalid_0's l2: 0.262574\n",
      "[I 2025-11-30 09:01:42,877] Trial 22 finished with value: 37973.17594217188 and parameters: {'n_estimators': 1192, 'max_depth': 8, 'num_leaves': 27, 'learning_rate': 0.07467181060583761, 'subsample': 0.5963798866156136, 'colsample_bytree': 0.5929447771660703, 'reg_alpha': 0.029941551181332356, 'reg_lambda': 0.015252393686683515}. Best is trial 21 with value: 37483.52336874395.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1428]\tvalid_0's l1: 0.376501\tvalid_0's l2: 0.25575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1460]\tvalid_0's l1: 0.378051\tvalid_0's l2: 0.257861\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1470]\tvalid_0's l1: 0.37671\tvalid_0's l2: 0.255988\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1452]\tvalid_0's l1: 0.372471\tvalid_0's l2: 0.248357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1215]\tvalid_0's l1: 0.377869\tvalid_0's l2: 0.257854\n",
      "[I 2025-11-30 09:04:44,801] Trial 23 finished with value: 37750.41968505507 and parameters: {'n_estimators': 1836, 'max_depth': 8, 'num_leaves': 50, 'learning_rate': 0.04356813675910001, 'subsample': 0.5403853239780476, 'colsample_bytree': 0.6323434691214229, 'reg_alpha': 0.056434783336359345, 'reg_lambda': 0.0024813543481540462}. Best is trial 21 with value: 37483.52336874395.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1467]\tvalid_0's l1: 0.378684\tvalid_0's l2: 0.257627\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1460]\tvalid_0's l1: 0.381484\tvalid_0's l2: 0.261054\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1460]\tvalid_0's l1: 0.378407\tvalid_0's l2: 0.257691\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1345]\tvalid_0's l1: 0.376759\tvalid_0's l2: 0.252083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1397]\tvalid_0's l1: 0.37901\tvalid_0's l2: 0.258699\n",
      "[I 2025-11-30 09:07:30,483] Trial 24 finished with value: 37490.66111179754 and parameters: {'n_estimators': 1467, 'max_depth': 9, 'num_leaves': 33, 'learning_rate': 0.032864601745638926, 'subsample': 0.503798996618278, 'colsample_bytree': 0.5402714880318089, 'reg_alpha': 0.28685514920757993, 'reg_lambda': 0.14464801557275822}. Best is trial 21 with value: 37483.52336874395.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's l1: 0.392818\tvalid_0's l2: 0.272906\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's l1: 0.394561\tvalid_0's l2: 0.274673\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[304]\tvalid_0's l1: 0.392768\tvalid_0's l2: 0.271959\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's l1: 0.388469\tvalid_0's l2: 0.263978\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid_0's l1: 0.391831\tvalid_0's l2: 0.271917\n",
      "[I 2025-11-30 09:08:07,956] Trial 25 finished with value: 38341.42356880027 and parameters: {'n_estimators': 1035, 'max_depth': 7, 'num_leaves': 32, 'learning_rate': 0.1700922625320053, 'subsample': 0.5016639269944434, 'colsample_bytree': 0.5625745711555045, 'reg_alpha': 0.209374245068206, 'reg_lambda': 1.5069254824434886}. Best is trial 21 with value: 37483.52336874395.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1260]\tvalid_0's l1: 0.379326\tvalid_0's l2: 0.25888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1260]\tvalid_0's l1: 0.38088\tvalid_0's l2: 0.260537\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1260]\tvalid_0's l1: 0.379404\tvalid_0's l2: 0.258827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1260]\tvalid_0's l1: 0.375422\tvalid_0's l2: 0.250461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1254]\tvalid_0's l1: 0.379288\tvalid_0's l2: 0.259041\n",
      "[I 2025-11-30 09:10:47,833] Trial 26 finished with value: 37360.48000685037 and parameters: {'n_estimators': 1261, 'max_depth': 9, 'num_leaves': 39, 'learning_rate': 0.027628896085505783, 'subsample': 0.8034998880597606, 'colsample_bytree': 0.5432065743593947, 'reg_alpha': 0.0349153100292941, 'reg_lambda': 0.15049036849934797}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[992]\tvalid_0's l1: 0.380441\tvalid_0's l2: 0.260423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[949]\tvalid_0's l1: 0.383291\tvalid_0's l2: 0.262225\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[939]\tvalid_0's l1: 0.379875\tvalid_0's l2: 0.259963\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[834]\tvalid_0's l1: 0.378401\tvalid_0's l2: 0.253982\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[593]\tvalid_0's l1: 0.382299\tvalid_0's l2: 0.262235\n",
      "[I 2025-11-30 09:12:36,234] Trial 27 finished with value: 38008.34824108526 and parameters: {'n_estimators': 1173, 'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.07294146083223704, 'subsample': 0.7917432760144621, 'colsample_bytree': 0.5447690905031324, 'reg_alpha': 0.013463782397016412, 'reg_lambda': 0.17709270604179259}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1330]\tvalid_0's l1: 0.380101\tvalid_0's l2: 0.25986\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1327]\tvalid_0's l1: 0.381345\tvalid_0's l2: 0.261056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1324]\tvalid_0's l1: 0.380007\tvalid_0's l2: 0.259273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1328]\tvalid_0's l1: 0.376353\tvalid_0's l2: 0.251013\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1323]\tvalid_0's l1: 0.380305\tvalid_0's l2: 0.259657\n",
      "[I 2025-11-30 09:15:10,184] Trial 28 finished with value: 37421.94361169911 and parameters: {'n_estimators': 1330, 'max_depth': 9, 'num_leaves': 33, 'learning_rate': 0.03179281019139127, 'subsample': 0.8295661924308242, 'colsample_bytree': 0.5318762919279235, 'reg_alpha': 0.3503484844281843, 'reg_lambda': 0.86758378744089}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[758]\tvalid_0's l1: 0.387239\tvalid_0's l2: 0.266675\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[393]\tvalid_0's l1: 0.389998\tvalid_0's l2: 0.271352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[479]\tvalid_0's l1: 0.388881\tvalid_0's l2: 0.268962\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's l1: 0.386238\tvalid_0's l2: 0.26164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[486]\tvalid_0's l1: 0.387343\tvalid_0's l2: 0.267358\n",
      "[I 2025-11-30 09:16:03,806] Trial 29 finished with value: 38330.55566165901 and parameters: {'n_estimators': 1320, 'max_depth': 9, 'num_leaves': 32, 'learning_rate': 0.12238817241458044, 'subsample': 0.8043987599783268, 'colsample_bytree': 0.6975610761927962, 'reg_alpha': 0.02295952256972524, 'reg_lambda': 1.297169854785375}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid_0's l1: 0.395396\tvalid_0's l2: 0.276098\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's l1: 0.397249\tvalid_0's l2: 0.27755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's l1: 0.395558\tvalid_0's l2: 0.276194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's l1: 0.392913\tvalid_0's l2: 0.268785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's l1: 0.396598\tvalid_0's l2: 0.276076\n",
      "[I 2025-11-30 09:16:35,226] Trial 30 finished with value: 38661.31602848171 and parameters: {'n_estimators': 1020, 'max_depth': 8, 'num_leaves': 39, 'learning_rate': 0.22351233353006741, 'subsample': 0.9233135465925875, 'colsample_bytree': 0.5223694792370291, 'reg_alpha': 4.5644027344749, 'reg_lambda': 4.17823674935931}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1510]\tvalid_0's l1: 0.379085\tvalid_0's l2: 0.25862\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1509]\tvalid_0's l1: 0.380328\tvalid_0's l2: 0.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1511]\tvalid_0's l1: 0.378153\tvalid_0's l2: 0.257453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1502]\tvalid_0's l1: 0.375936\tvalid_0's l2: 0.25182\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1507]\tvalid_0's l1: 0.378286\tvalid_0's l2: 0.257422\n",
      "[I 2025-11-30 09:19:22,646] Trial 31 finished with value: 37637.10724783856 and parameters: {'n_estimators': 1511, 'max_depth': 9, 'num_leaves': 35, 'learning_rate': 0.034421077882187456, 'subsample': 0.800619750020349, 'colsample_bytree': 0.5676328714711449, 'reg_alpha': 0.27266490724046766, 'reg_lambda': 0.15618392616799576}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1278]\tvalid_0's l1: 0.381723\tvalid_0's l2: 0.261693\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1279]\tvalid_0's l1: 0.383645\tvalid_0's l2: 0.263865\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1279]\tvalid_0's l1: 0.381062\tvalid_0's l2: 0.260851\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1279]\tvalid_0's l1: 0.37952\tvalid_0's l2: 0.254312\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1276]\tvalid_0's l1: 0.381664\tvalid_0's l2: 0.261092\n",
      "[I 2025-11-30 09:21:31,012] Trial 32 finished with value: 37439.78122817694 and parameters: {'n_estimators': 1279, 'max_depth': 9, 'num_leaves': 32, 'learning_rate': 0.027845080423270274, 'subsample': 0.7370878516541505, 'colsample_bytree': 0.6222037631958409, 'reg_alpha': 0.08457578784105856, 'reg_lambda': 0.5187366993845217}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1164]\tvalid_0's l1: 0.380903\tvalid_0's l2: 0.26058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1267]\tvalid_0's l1: 0.383652\tvalid_0's l2: 0.263347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1113]\tvalid_0's l1: 0.381685\tvalid_0's l2: 0.262146\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1223]\tvalid_0's l1: 0.377907\tvalid_0's l2: 0.253592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1002]\tvalid_0's l1: 0.382354\tvalid_0's l2: 0.262396\n",
      "[I 2025-11-30 09:23:17,607] Trial 33 finished with value: 37964.93027370756 and parameters: {'n_estimators': 1267, 'max_depth': 9, 'num_leaves': 30, 'learning_rate': 0.06917031340857419, 'subsample': 0.8319017082126366, 'colsample_bytree': 0.6164145483933634, 'reg_alpha': 0.08342861600588275, 'reg_lambda': 0.4912606792629999}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[904]\tvalid_0's l1: 0.384542\tvalid_0's l2: 0.263437\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[903]\tvalid_0's l1: 0.386098\tvalid_0's l2: 0.265598\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[908]\tvalid_0's l1: 0.383084\tvalid_0's l2: 0.262917\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[908]\tvalid_0's l1: 0.381009\tvalid_0's l2: 0.256374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[894]\tvalid_0's l1: 0.383414\tvalid_0's l2: 0.262991\n",
      "[I 2025-11-30 09:25:03,434] Trial 34 finished with value: 37449.930760623705 and parameters: {'n_estimators': 908, 'max_depth': 9, 'num_leaves': 32, 'learning_rate': 0.030019846287119407, 'subsample': 0.7382819973685085, 'colsample_bytree': 0.567509790116652, 'reg_alpha': 0.05758426899096187, 'reg_lambda': 0.6802442643047684}. Best is trial 26 with value: 37360.48000685037.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[895]\tvalid_0's l1: 0.385893\tvalid_0's l2: 0.265595\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[901]\tvalid_0's l1: 0.386511\tvalid_0's l2: 0.266102\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[901]\tvalid_0's l1: 0.383984\tvalid_0's l2: 0.263742\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[901]\tvalid_0's l1: 0.3811\tvalid_0's l2: 0.256669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[901]\tvalid_0's l1: 0.384445\tvalid_0's l2: 0.264155\n",
      "[I 2025-11-30 09:26:53,585] Trial 35 finished with value: 37282.96999494691 and parameters: {'n_estimators': 901, 'max_depth': 9, 'num_leaves': 39, 'learning_rate': 0.02111239612639956, 'subsample': 0.7321531218714541, 'colsample_bytree': 0.6615908637839784, 'reg_alpha': 0.05273684287506279, 'reg_lambda': 0.6809417448987716}. Best is trial 35 with value: 37282.96999494691.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[664]\tvalid_0's l1: 0.390112\tvalid_0's l2: 0.269119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[664]\tvalid_0's l1: 0.39118\tvalid_0's l2: 0.269743\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[663]\tvalid_0's l1: 0.388537\tvalid_0's l2: 0.267942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[662]\tvalid_0's l1: 0.385618\tvalid_0's l2: 0.260368\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[664]\tvalid_0's l1: 0.389776\tvalid_0's l2: 0.269123\n",
      "[I 2025-11-30 09:28:18,199] Trial 36 finished with value: 37428.45497971406 and parameters: {'n_estimators': 664, 'max_depth': 9, 'num_leaves': 38, 'learning_rate': 0.018539786743873753, 'subsample': 0.7382081645285086, 'colsample_bytree': 0.6602645718111559, 'reg_alpha': 0.006937486990514388, 'reg_lambda': 2.6349534948879865}. Best is trial 35 with value: 37282.96999494691.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[693]\tvalid_0's l1: 0.390931\tvalid_0's l2: 0.269822\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[693]\tvalid_0's l1: 0.391927\tvalid_0's l2: 0.270653\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[693]\tvalid_0's l1: 0.389151\tvalid_0's l2: 0.268966\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[693]\tvalid_0's l1: 0.386923\tvalid_0's l2: 0.261623\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[693]\tvalid_0's l1: 0.390806\tvalid_0's l2: 0.269646\n",
      "[I 2025-11-30 09:29:49,239] Trial 37 finished with value: 37445.24486562621 and parameters: {'n_estimators': 693, 'max_depth': 9, 'num_leaves': 39, 'learning_rate': 0.016508329838963488, 'subsample': 0.778122549638021, 'colsample_bytree': 0.6645937671245415, 'reg_alpha': 0.007987963807189705, 'reg_lambda': 2.912372527726412}. Best is trial 35 with value: 37282.96999494691.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[559]\tvalid_0's l1: 0.396787\tvalid_0's l2: 0.275525\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[559]\tvalid_0's l1: 0.398507\tvalid_0's l2: 0.277381\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[559]\tvalid_0's l1: 0.396153\tvalid_0's l2: 0.275717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[559]\tvalid_0's l1: 0.391783\tvalid_0's l2: 0.26709\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[559]\tvalid_0's l1: 0.397215\tvalid_0's l2: 0.276423\n",
      "[I 2025-11-30 09:31:16,123] Trial 38 finished with value: 37995.291434566156 and parameters: {'n_estimators': 559, 'max_depth': 9, 'num_leaves': 45, 'learning_rate': 0.0107266085711558, 'subsample': 0.8778032079682576, 'colsample_bytree': 0.7229952627172153, 'reg_alpha': 0.0054082910565712615, 'reg_lambda': 2.399230225808309}. Best is trial 35 with value: 37282.96999494691.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[682]\tvalid_0's l1: 0.383014\tvalid_0's l2: 0.262985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[791]\tvalid_0's l1: 0.382557\tvalid_0's l2: 0.26275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[795]\tvalid_0's l1: 0.381504\tvalid_0's l2: 0.261545\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[615]\tvalid_0's l1: 0.37843\tvalid_0's l2: 0.253421\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[805]\tvalid_0's l1: 0.381557\tvalid_0's l2: 0.261264\n",
      "[I 2025-11-30 09:32:39,956] Trial 39 finished with value: 37719.13203046261 and parameters: {'n_estimators': 805, 'max_depth': 9, 'num_leaves': 38, 'learning_rate': 0.06347738750289533, 'subsample': 0.8296265264269413, 'colsample_bytree': 0.6767135584665958, 'reg_alpha': 0.002315093004316234, 'reg_lambda': 0.288511573196898}. Best is trial 35 with value: 37282.96999494691.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[746]\tvalid_0's l1: 0.383529\tvalid_0's l2: 0.26333\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[623]\tvalid_0's l1: 0.384673\tvalid_0's l2: 0.263626\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[729]\tvalid_0's l1: 0.38233\tvalid_0's l2: 0.26325\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[649]\tvalid_0's l1: 0.37796\tvalid_0's l2: 0.253992\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[436]\tvalid_0's l1: 0.38269\tvalid_0's l2: 0.262823\n",
      "[I 2025-11-30 09:34:04,725] Trial 40 finished with value: 37726.616309832854 and parameters: {'n_estimators': 941, 'max_depth': 9, 'num_leaves': 43, 'learning_rate': 0.08836993140730495, 'subsample': 0.9326395988334534, 'colsample_bytree': 0.7279773412356982, 'reg_alpha': 0.009101301129662318, 'reg_lambda': 6.011326913573323}. Best is trial 35 with value: 37282.96999494691.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1242]\tvalid_0's l1: 0.378939\tvalid_0's l2: 0.258892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1244]\tvalid_0's l1: 0.381108\tvalid_0's l2: 0.260923\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1235]\tvalid_0's l1: 0.378658\tvalid_0's l2: 0.258777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1241]\tvalid_0's l1: 0.376501\tvalid_0's l2: 0.2521\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1243]\tvalid_0's l1: 0.379151\tvalid_0's l2: 0.258961\n",
      "[I 2025-11-30 09:36:29,391] Trial 41 finished with value: 37314.19254584834 and parameters: {'n_estimators': 1244, 'max_depth': 9, 'num_leaves': 40, 'learning_rate': 0.02760099091570941, 'subsample': 0.7343242126104096, 'colsample_bytree': 0.6307677435020137, 'reg_alpha': 0.10666717293869125, 'reg_lambda': 0.749784450339733}. Best is trial 35 with value: 37282.96999494691.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[701]\tvalid_0's l1: 0.381281\tvalid_0's l2: 0.261169\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[701]\tvalid_0's l1: 0.38181\tvalid_0's l2: 0.261947\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[697]\tvalid_0's l1: 0.380039\tvalid_0's l2: 0.259808\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[700]\tvalid_0's l1: 0.377285\tvalid_0's l2: 0.253204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[701]\tvalid_0's l1: 0.380164\tvalid_0's l2: 0.260587\n",
      "[I 2025-11-30 09:38:04,093] Trial 42 finished with value: 37264.19422884955 and parameters: {'n_estimators': 701, 'max_depth': 9, 'num_leaves': 47, 'learning_rate': 0.03556399037426114, 'subsample': 0.7200127581769322, 'colsample_bytree': 0.6383019441303173, 'reg_alpha': 0.14754187478676065, 'reg_lambda': 0.8288652743106274}. Best is trial 42 with value: 37264.19422884955.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1120]\tvalid_0's l1: 0.378101\tvalid_0's l2: 0.257252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1113]\tvalid_0's l1: 0.379072\tvalid_0's l2: 0.259267\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1117]\tvalid_0's l1: 0.37688\tvalid_0's l2: 0.256401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1119]\tvalid_0's l1: 0.373802\tvalid_0's l2: 0.249662\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1096]\tvalid_0's l1: 0.377965\tvalid_0's l2: 0.257546\n",
      "[I 2025-11-30 09:40:27,028] Trial 43 finished with value: 37502.82335369249 and parameters: {'n_estimators': 1120, 'max_depth': 9, 'num_leaves': 48, 'learning_rate': 0.04221689803065229, 'subsample': 0.6745256943030105, 'colsample_bytree': 0.6385922161904859, 'reg_alpha': 0.1510402288380694, 'reg_lambda': 0.9091349936437899}. Best is trial 42 with value: 37264.19422884955.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's l1: 0.40431\tvalid_0's l2: 0.285558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's l1: 0.403031\tvalid_0's l2: 0.284996\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's l1: 0.400961\tvalid_0's l2: 0.283637\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's l1: 0.396344\tvalid_0's l2: 0.27363\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's l1: 0.402459\tvalid_0's l2: 0.284597\n",
      "[I 2025-11-30 09:40:49,528] Trial 44 finished with value: 39335.174297249665 and parameters: {'n_estimators': 965, 'max_depth': 9, 'num_leaves': 47, 'learning_rate': 0.2522873571181165, 'subsample': 0.7702523064455207, 'colsample_bytree': 0.524421066238548, 'reg_alpha': 0.053130222590419475, 'reg_lambda': 0.048377095882208676}. Best is trial 42 with value: 37264.19422884955.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[783]\tvalid_0's l1: 0.380713\tvalid_0's l2: 0.260162\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[783]\tvalid_0's l1: 0.383454\tvalid_0's l2: 0.262816\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[662]\tvalid_0's l1: 0.381348\tvalid_0's l2: 0.261318\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[783]\tvalid_0's l1: 0.376876\tvalid_0's l2: 0.253189\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[768]\tvalid_0's l1: 0.381079\tvalid_0's l2: 0.26013\n",
      "[I 2025-11-30 09:42:24,378] Trial 45 finished with value: 37620.99854880739 and parameters: {'n_estimators': 783, 'max_depth': 9, 'num_leaves': 41, 'learning_rate': 0.060957623298714084, 'subsample': 0.718800991482047, 'colsample_bytree': 0.5943257984729854, 'reg_alpha': 0.5931948793072238, 'reg_lambda': 1.6709058833369996}. Best is trial 42 with value: 37264.19422884955.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1396]\tvalid_0's l1: 0.378416\tvalid_0's l2: 0.258131\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1398]\tvalid_0's l1: 0.380182\tvalid_0's l2: 0.260421\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1073]\tvalid_0's l1: 0.378006\tvalid_0's l2: 0.257314\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1071]\tvalid_0's l1: 0.37473\tvalid_0's l2: 0.250515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[920]\tvalid_0's l1: 0.379391\tvalid_0's l2: 0.259583\n",
      "[I 2025-11-30 09:44:59,426] Trial 46 finished with value: 37695.99205318875 and parameters: {'n_estimators': 1398, 'max_depth': 9, 'num_leaves': 46, 'learning_rate': 0.04496797209410124, 'subsample': 0.6536792069722375, 'colsample_bytree': 0.770830649628145, 'reg_alpha': 0.11341719030904189, 'reg_lambda': 0.2336505395020509}. Best is trial 42 with value: 37264.19422884955.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1227]\tvalid_0's l1: 0.380632\tvalid_0's l2: 0.26064\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1223]\tvalid_0's l1: 0.38251\tvalid_0's l2: 0.262786\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1226]\tvalid_0's l1: 0.379534\tvalid_0's l2: 0.259181\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1225]\tvalid_0's l1: 0.376937\tvalid_0's l2: 0.252719\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1227]\tvalid_0's l1: 0.38077\tvalid_0's l2: 0.260085\n",
      "[I 2025-11-30 09:47:25,461] Trial 47 finished with value: 37348.307339149105 and parameters: {'n_estimators': 1227, 'max_depth': 9, 'num_leaves': 41, 'learning_rate': 0.023950519025516585, 'subsample': 0.8524353235962876, 'colsample_bytree': 0.642588400759266, 'reg_alpha': 0.21035794470641359, 'reg_lambda': 0.5108552559349446}. Best is trial 42 with value: 37264.19422884955.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1217]\tvalid_0's l1: 0.380815\tvalid_0's l2: 0.261175\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1216]\tvalid_0's l1: 0.382054\tvalid_0's l2: 0.262097\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1220]\tvalid_0's l1: 0.379754\tvalid_0's l2: 0.259795\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1214]\tvalid_0's l1: 0.377566\tvalid_0's l2: 0.253004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1220]\tvalid_0's l1: 0.380448\tvalid_0's l2: 0.260313\n",
      "[I 2025-11-30 09:49:56,354] Trial 48 finished with value: 37234.12316006522 and parameters: {'n_estimators': 1220, 'max_depth': 9, 'num_leaves': 43, 'learning_rate': 0.02074682427599503, 'subsample': 0.863446330104126, 'colsample_bytree': 0.6365746932255311, 'reg_alpha': 0.17339709031287434, 'reg_lambda': 0.43706016792221175}. Best is trial 48 with value: 37234.12316006522.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162188\n",
      "[LightGBM] [Info] Number of data points in the train set: 61428, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.465115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[312]\tvalid_0's l1: 0.3867\tvalid_0's l2: 0.266674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162195\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.460179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[311]\tvalid_0's l1: 0.387272\tvalid_0's l2: 0.267927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162205\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.455948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[309]\tvalid_0's l1: 0.385074\tvalid_0's l2: 0.265349\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162201\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.457530\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[310]\tvalid_0's l1: 0.381308\tvalid_0's l2: 0.257489\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162220\n",
      "[LightGBM] [Info] Number of data points in the train set: 61429, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.467747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[304]\tvalid_0's l1: 0.385595\tvalid_0's l2: 0.265852\n",
      "[I 2025-11-30 09:50:38,256] Trial 49 finished with value: 37668.485015284576 and parameters: {'n_estimators': 312, 'max_depth': 9, 'num_leaves': 44, 'learning_rate': 0.0967261270581348, 'subsample': 0.9128620839025657, 'colsample_bytree': 0.6466214612006181, 'reg_alpha': 0.2152144244052651, 'reg_lambda': 0.494893436436659}. Best is trial 48 with value: 37234.12316006522.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"lgbm_opt\", direction=\"minimize\")\n",
    "study.optimize(objective_lgbm, n_trials=50, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "b10cfb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value (WMAE): 37234.12316006522\n",
      "Best params: {'n_estimators': 1220, 'max_depth': 9, 'num_leaves': 43, 'learning_rate': 0.02074682427599503, 'subsample': 0.863446330104126, 'colsample_bytree': 0.6365746932255311, 'reg_alpha': 0.17339709031287434, 'reg_lambda': 0.43706016792221175}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best value (WMAE):\", study.best_value)\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "f6d7711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_reg = lightgbm.LGBMRegressor(**study.best_trial.params, max_bin=1000, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d3707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163315\n",
      "[LightGBM] [Info] Number of data points in the train set: 76786, number of used features: 220\n",
      "[LightGBM] [Info] Start training from score 11.461311\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.6365746932255311,\n",
       "              learning_rate=0.02074682427599503, max_bin=1000, max_depth=9,\n",
       "              n_estimators=1220, num_leaves=43, random_state=23,\n",
       "              reg_alpha=0.17339709031287434, reg_lambda=0.43706016792221175,\n",
       "              subsample=0.863446330104126)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMRegressor</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">43</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.02074682427599503</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">1220</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.863446330104126</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.6365746932255311</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.17339709031287434</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.43706016792221175</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">23</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.6365746932255311,\n",
       "              learning_rate=0.02074682427599503, max_bin=1000, max_depth=9,\n",
       "              n_estimators=1220, num_leaves=43, random_state=23,\n",
       "              reg_alpha=0.17339709031287434, reg_lambda=0.43706016792221175,\n",
       "              subsample=0.863446330104126)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_reg.fit(X, y, sample_weight=train_df['w'], callbacks=[lightgbm.log_evaluation(period=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "4d3e46bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lightgbm.plot_importance(lgbm_reg, max_num_features=10, figsize=(8,6))\n",
    "plt.title('Feature importance LightGBM (top 10)')\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WMAE = weighted_mean_absolute_error(train_df['target'], train_df['predict'], train_df['w'])\n",
    "# print(f\"WMAE = {WMAE:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1d2bb",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[object_col] = test_df[object_col].astype('category')\n",
    "preds = lgbm_reg.predict(test_df.drop(columns=['id', 'dt']))\n",
    "result = pd.DataFrame(data={'ID':test_df['id'], 'target':preds})\n",
    "result.to_csv(\"submission.csv\", index=False, decimal='.', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0b4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
